% Template for a Computer Science Tripos Part II project dissertation
\documentclass[12pt,a4paper,twoside,openright]{report}
\usepackage[pdfborder={0 0 0}]{hyperref}    % turns references into hyperlinks
\usepackage[margin=25mm]{geometry}  % adjusts page layout
\usepackage{graphicx}  % allows inclusion of PDF, PNG and JPG images
\usepackage{verbatim}
\usepackage{docmute}   % only needed to allow inclusion of proposal.tex
\usepackage{tikz}
\usetikzlibrary{shapes.geometric, arrows}
\usepackage{multirow}
\usepackage{url}
\usepackage{csquotes}
\usepackage{float}
\usepackage{textcomp}
\usetikzlibrary{positioning}
\usetikzlibrary{arrows.meta}
 
% Conditionals (for draft mode)
\usepackage{ifthen}

% Color
\usepackage{color}

% Date/time stuff
\usepackage{datetime}

\usepackage{xspace}

%    THIS IS THE BIG DRAFT SWITCH
% FLICK THIS AND the todo notes and watermark disappear/appear


\newboolean{draft}
\setboolean{draft}{true}

\newboolean{comments}

\ifdraft
  \setboolean{comments}{true}
\else
  \setboolean{comments}{false}
\fi

\newcommand\todo[1]{\ifcomments{\color{cyan}{\bf ToDo: #1}}\fi}

\newcommand\note[2]{{\color{#1}\bf #2}}
\newcommand\awm[1]{\ifcomments{\note{blue}{AM: #1}}\fi}
\newcommand\simon[1]{\ifcomments{\note{cyan}{SM: #1}}\fi}
% Watermark in draft mode
% Draft watermark
\ifdraft
\usepackage{calc} 
\usepackage{ifthen} 
\newcounter{hours}\newcounter{minutes} 
\newcommand\printtime{% 
  \setcounter{hours}{\time/60}% 
  \setcounter{minutes}{\time-\value{hours}*60}% 
  \ifthenelse{\value{hours}<10}{0\thehours}{\thehours}:\hspace{-0.33em} 
  \ifthenelse{\value{minutes}<10}{0\theminutes}{\theminutes} 
} 

 \usepackage{draftwatermark}
 \SetWatermarkScale{1.1}
 \SetWatermarkLightness{0.9}
 \SetWatermarkText{\shortstack{DRAFT  \\[0.5cm] {\fontsize{38}{12}\selectfont 
         %\selectlanguage{<language>}
         \today, {\currenttime}}%, \printtime
     }}
  \fi


\raggedbottom                           % try to avoid widows and orphans
\sloppy
\clubpenalty1000%
\widowpenalty1000%

\renewcommand{\baselinestretch}{1.1}    % adjust line spacing to make
                                        % more readable

\begin{document}

\bibliographystyle{plain}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Title


\pagestyle{empty}

\rightline{\LARGE \textbf{Simonas Mulevicius}}
% Blind Grading Number == 2439D

\vspace*{60mm}
\begin{center}
\Huge
\textbf{Examining \texttt{QUIC}} \\[5mm]
Computer Science Tripos -- Part II \\[5mm]
Homerton College \\[5mm]
\today  % today's date
\end{center}








\newpage



\section*{Declaration of Originality}

I, Simonas Mulevicius of Homerton College, being a candidate for Part II of the Computer
Science Tripos, hereby declare
that this dissertation and the work described in it are my own work,
unaided except as may be specified below, and that the dissertation
does not contain material that has already been used to any substantial
extent for a comparable purpose. I am content for my dissertation to
be made available to the students and staff of the University.

\bigskip
\leftline{Signed [signature]}

\medskip
\leftline{Date [date]}


\newpage










%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Proforma, table of contents and list of figures

\pagestyle{plain}

\chapter*{Proforma}

{\large
\begin{tabular}{ll}
Candidate Number:               & \bf 2439D                      \\
College:            & \bf Homerton College                     \\
Project Title:      & \bf \texttt{QUIC} offloading using NetFPGA smart NICs \\
Examination:        & \bf Computer Science Tripos -- Part II, July 2021  \\
Word Count:         & \bf 7996\footnotemark[1] \\
Project Originator: & Professor Andrew W. Moore                \\
Supervisor:         & Professor Andrew W. Moore                \\ 
\end{tabular}
}
\footnotetext[1]{This word count was computed
by \texttt{DISS\_LENGTH=\$(detex diss.tex | tr -cd '0-9A-Za-z $\tt\backslash$n' | wc -w); PROPOSAL\_LENGTH=\$(detex proposal.tex | tr -cd '0-9A-Za-z $\tt\backslash$n' | wc -w); echo "\$((\$DISS\_LENGTH-\$PROPOSAL\_LENGTH))"}}

\stepcounter{footnote}


\section*{Original Aims of the Project}

The initial primary goal of the project was to offload packet reordering logic of \texttt{QUIC} to hardware.
However, because of the increased project complexity due to the COVID-19 leading to an unexpectedly long preparation phase, difficulties in system access, and challenges with the \texttt{NetFPGA SUME} boards, I changed the primary focus of the project.
Hence, the adjusted goals of this dissertation are to study the behaviour of \texttt{QUIC} under different network conditions, to measure the impact of network perturbations for the throughput of \texttt{QUIC}, and identify bottleneck in \texttt{QUIC} implementations.

\section*{Work Completed}

I configured a network emulation  and testing environment allowing the performance measurements of \texttt{QUIC}.
Then, I measured \texttt{QUIC} throughput under different network conditions, e.g., when I applied additional packet delay, packet loss, and packet reordering.

\section*{Special Difficulties}

The initial goal of the project was to write hardware components in \texttt{Verilog} that would offload packet reordering logic of \texttt{QUIC} packets to hardware.
For this project, I had access to two dedicated experimental machines equipped with specialised hardware components -- \texttt{NetFPGA SUME} network interface cards.
However, the software and hardware stack of \texttt{NetFPGA} platform was relatively complex.
For instance, it took me unexpectedly long to prepare, configure and test the correct functionality of \texttt{NetFPGA SUME} boards because, as I have already mentioned, COVID-19 complicated the set-up process.

To simplify the development process I had a pair of the aforementioned machines in my college room.
However, I faced accessibility issues during the winter vacation when I was abroad at home.
In particular, the testing machines were expensive, heavy and fragile so I could not take them with me for the winter vacation.
Hence, to overcome this issue I had to configure remote access of the testing environment.
I spent more than one month working on the remote set-up of both the main pair of testing machines as well as the backup pair.
Unfortunately, I could not configure two additional backup machines in the Computer Laboratory.
A suspected issue was a possible hardware fault.
Hence, to continue working on the project, I had to return to my college room.
This lengthy preparation phase substantially delayed the actual development of the project.
As a result, after consultation with the project supervisor I decided to change the focus of the dissertation from hardware offloading to the software-oriented performance analysis of \texttt{QUIC}. 
In conclusion, one could argue that in the pre-pandemic times, physical access to the pre-configured and tested hardware could have saved me a lot of time.


%Professional Practice and Presentation 14%
%Introduction and Preparation 26%
%Implementation 40%
%Evaluation and Conclusion 20%




\tableofcontents

\listoffigures

\newpage
\section*{Acknowledgements}

The following people helped with the project setup or provided useful insights or hints on how to tackle project-related problems:
\begin{itemize}
    \item \textbf{Dr Marcin Wojcik} helped with general inquiries related to the setup of NetFPGA developing platform;
    \item \textbf{Professor Andrew W. Moore} was my project supervisor and originator of the project idea;
    \item \textbf{Dr Malcolm Scott} helped with the configuration of two remote backup machines in the Computer Laboratory during the winter vacation;
    \item \textbf{Mr Tatsuhiro Tsujikawa} is the author of the \texttt{ngtcp2} implementation of \texttt{QUIC}, and he answered usability questions related to it. Moreover, he provided guidance on how null encryption could be turned on in \texttt{ngtcp2};
    \item \textbf{Mr Nick Banks}, software developer from \texttt{Microsoft}, is the co-author of the \texttt{MsQuic} implementation of \texttt{QUIC}, and he helped with the setup of this particular implementation of \texttt{QUIC};
    \item Part II students \textbf{Ms Akvile Valentukonyte} and \textbf{Mr Justas Janickas} participated in our weekly meetings where we all shared our achieved progress;
\end{itemize}

Furthermore, this document is written using a default dissertation template provided by Martin Richards~\cite{how_to_write_a_dissertation_in_LATEX}.
However, some formatting ideas are taken from Alex Coplan's dissertation~\cite{Alex_Coplan_dissertation}, which is \enquote{highly commended by the examiners}~\cite{Computer_Lab_dissertations}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% now for the chapters

\pagestyle{headings}

\chapter{Introduction}

% ------------------------------------------------
% TODO
%
% The introduction should explain the principal motivation for the project and show how the work fits into the broad area of surrounding computer science and give a brief survey of previous related work. It should generally be unnecessary to quote at length from technical papers or textbooks. If a simple bibliographic reference is insufficient, consign any lengthy quotation to an appendix.



% FROM: https://www.cst.cam.ac.uk/teaching/part-ii/projects/assessment
% Clear motivation, justifying potential benefits of success.
%Good or excellent requirements analysis; justified and documented selection of suitable tools; good engineering approach.
%Clear presentation of challenging background material covering a range of computer science topics beyond Part IB.
% ------------------------------------------------



% TODO: say what the problem is
% > explain the problem
% > why is the problem interesting?
% > why does the solution enable?

% TODO: describe my work
% > how does my work solve the problem (high-level overview)?
% > details in other chapters



% TODO add reference to the ideas of this paragraph:
Nowadays, more and more people have access to the Internet.
As the scale of the web continues to grow, both companies and researchers look for ways to satisfy ever-increasing market demand to improve the user experience of Internet users.
Customers expect cheap, high-throughput and low latency Internet connections.
However, in the last decade, several trends have emerged.
For example, in recent years, we observed a proliferation of mobile devices -- at the time of writing, around $92.6\%$ of Internet users used mobile devices to connect to the Internet~\cite{bib_number_of_mobile_users}.
Furthermore, we see the changing patterns of web development.
In particular, usual websites nowadays contain multiple embedded objects of various sizes (e.g. from \texttt{JavaScript} or \texttt{CSS} files to numerous images and videos)\cite{bib_Netdev_0x13_QUIC_Tutorial}.
But, these websites look entirely different from the simple, single document \texttt{HTML} websites used in the early days of the Internet~\cite{RudmanRiaan2016DW3o}.
Hence, the changing constraints and networking trends encourage us to re-evaluate past protocols.
By using innovative solutions, we can continue improving the performance of the Internet. 
One of such ideas is \texttt{QUIC} -- the new transport layer protocol.

\section{Motivation of the Project}

The purpose of this dissertation is to understand \texttt{QUIC}.
As I describe in the later chapters, this innovative transport layer protocol offers both performance and privacy improvements.
However, \texttt{QUIC} has many new features that are either not present in \texttt{TCP} or that are used in different ways.
Hence, because of this novelty, performance behaviour of \texttt{QUIC} is usually not well understood.
Thus, in this project I seek to understand several key features of \texttt{QUIC} that determine its performance.
Then, I analyse existing implementations of \texttt{QUIC} aiming to identify their performance bottlenecks.
Finally, this analysis could provide guidance for further \texttt{QUIC} improvements that could lead to the most immediate effects.


\section{Objectives of the Project}

The primary primary goal of this project is to identify the bottlenecks of \texttt{QUIC} and characterise its performance behaviour.
\texttt{QUIC} transport layer protocol is a new protocol.
However, it is already necessary to start thinking about its performance.
Otherwise, the low throughput of \texttt{QUIC} may prevent it from being widely adopted (as happened with earlier attempts to improve \texttt{TCP}). 
% TODO: add a reference to the source proving this claim


% ----------------------------------------------
% Removed according to Andrew's recommendations:
% ----------------------------------------------
% <START_OF_REMOVAL>
%The most interesting part of this project is that  \texttt{QUIC} is a relatively new network technology and, as far as I am aware, there have not been any similar projects which tried to measure \texttt{QUIC}’s performance by \enquote{breaking} it (i.e. using \texttt{QUIC} without encryption).
% TODO
%[TODO: incorrect - Mr  Nick  Banks proposed null-crypto option already in autumn of 2020 but I was not aware of that]

% This analysis could be useful in the future when \texttt{QUIC}’s cryptographic operations would be offloaded to hardware. Nevertheless, these experiments could also have some tangible value for current times. 
% For instance, an experimental \texttt{QUIC} with null encryption could be used in secure networks controlled by a single entity (e.g. within a data centre).
% Alternatively, unencrypted \texttt{QUIC} traffic could be used to isolate expensive cryptographic operations from the performance analysis of \texttt{QUIC}, as suggested in~\cite{banks-quic-disable-encryption-00}.
% <END_OF_REMOVAL>
% ----------------------------------------------





%-------IDEAS to add to this section:-------


%The performance study of \texttt{QUIC} under several variable conditions (e.g. packet loss, reordering and delay) in comparison with iperf is the focus of my work.
 
 
%The purpose of this work is to predict future bottlenecks. To achieve this, I would first need to exclude/bypass the cryptographic operations of  \texttt{QUIC}. I already have the functionality to turn on null-encryption on the server-side, so I would need to adopt similar ideas for the  \texttt{QUIC} client. Such a set-up would simulate offloaded encryption. Previous studies analysed different implementations of  \texttt{QUIC} (not ngtcp2), so the primary goal would be to run similar experiments with ngtcp2. After that, I would have to identify situations where  \texttt{QUIC} (ngtcp2 in particular) outperforms TCP using different network conditions. To achieve this, I have a complete testing environment with a configured intermediate machine that can introduce traffic perturbations. In addition, I have already performed some performance measurements using different MTUs. Furthermore, I estimated the impact of core pinning for these tests and took into account both hyperthreading and GSO.
 
 

\subsection{High-Level Overview of \texttt{QUIC}}
I detail \texttt{QUIC} in the later sections of the dissertation (see section~\ref{QUIC_details_section}) but, briefly speaking, \texttt{QUIC} is a new transport layer protocol that combines ideas of \texttt{TCP}, \texttt{HTTP} and other experimental protocols such as \texttt{SPDY} (which is also briefly mentioned in the later sections -- see \ref{Previous_attempt_to_improve_http_by_using_SPDY_and_HTTP2}).
On the one hand, \texttt{QUIC} breaks the separation of transport and security layer protocols. 
On the other hand, \texttt{QUIC} protocol offers some performance benefits for modern-day traffic flows (see section~\ref{QUIC_advantages}).


\subsection{Importance of Performance Measurements of \texttt{QUIC}}

\texttt{QUIC}, after being publicly launched in 2013~\cite{Chromium_Blog_Experimenting_with_quic},  is still a relatively new protocol that is still in the development stage.
Hence, any performance measurements of \texttt{QUIC} guide the ongoing efforts to improve this new transport layer protocol.
Furthermore, there are strong indications showing that \texttt{QUIC} could be widely adopted in the future.
For instance, \texttt{Google}, one of the major advocates for \texttt{QUIC}, operates both on the server side (e.g. search engine or video streaming service \texttt{YouTube}) and the client side (e.g. \texttt{Google Chrome} browser for desktop and mobile devices)~\cite{A_QUICk_Introduction_to_HTTP3}.
Hence, using its existing market presence \texttt{Google} could potentially encourage the faster adoption of \texttt{QUIC}.
Actually, according to the report published in 2016~\cite{RuthJan2018AFLa}, at that time around 40\% of all traffic of \texttt{Google} was using \texttt{QUIC}.
Similarly, other large technology companies such as \texttt{Facebook} or \texttt{Microsoft} are also building their own implementations of \texttt{QUIC} (correspondingly \texttt{mvfst}\footnote{https://github.com/facebookincubator/mvfst} and \texttt{MsQuic}\footnote{https://github.com/microsoft/msquic}).
These companies are also pushing the deployment of \texttt{QUIC}. 
For example, according to the report from \texttt{Facebook} published in 2020~\cite{how-facebook-is-bringing-quic-to-billions}, \texttt{QUIC} was used for the three quarters of \texttt{Facebook} traffic. 
In conclusion, it is highly likely that \texttt{QUIC} would get wide range of support meaning that current performance measurements of \texttt{QUIC} could help shape the future.

\section{Related Work}
There have been several similar attempts to measure \texttt{QUIC} performance under different network scenarios. 
Yang et al.~\cite{Making_QUIC_Quicker} analysed the impact of network delay, packet reordering and packet delay for the \texttt{QUIC} throughput; the authors examine several different implementations of \texttt{QUIC} written in the C/C\texttt{++} language family.
Their performance analysis of \texttt{QUIC} used two machines -- one hosted both the client and the server while the second machine introduced controlled network perturbations.
As illustrated in Figure~\ref{fig:Physical_testing_environment}, I also used this setup for my performance analysis of \texttt{QUIC}.
In addition, Yang et al.~\cite{Making_QUIC_Quicker} show that slight packet reordering can substantially decrease the throughput of \texttt{QUIC} .
They then suggest that one reason for such behaviour is that reordered packets can be treated as lost packets~\cite{Making_QUIC_Quicker}. 


In order to measure the impact of cryptography for \texttt{QUIC} performance, I extended one implementation of \texttt{QUIC} to support \enquote{Null-encryption}.
However, later I discovered that the option to disable encryption of \texttt{QUIC} was already proposed~\cite{banks-quic-disable-encryption-00}.
The author noted in private correspondence that this ideas had been already implemented in \texttt{MsQuic}, the aforementioned \texttt{Microsoft}'s implementation of \texttt{QUIC}.



An analysis of the \texttt{QUIC} protocol was published in 2018~\cite{overview_of_the_QUIC_protocol}.
We both use the same implementation of \texttt{QUIC}, called \texttt{ngtcp2}.
Indeed, \texttt{ngtcp2} has a well-documented code-base with several examples, e.g., client and server implementations.   
However, \texttt{QUIC} in 2018 was still in the early development stage as it had only been publicaly published for several years~\cite{Chromium_Blog_Experimenting_with_quic}.
Sanadhi~\cite{overview_of_the_QUIC_protocol} focused on the correctness of \texttt{ngtcp2} and another implementation of \texttt{QUIC} called \texttt{gQUIC}.
They inspected the correct order of packet exchange, although no quantitative performance analysis of the protocol was performed.
Nevertheless, in the \enquote{Future work} chapter the author suggests carrying out a performance analysis of \texttt{QUIC} under different simulated network conditions.
As a result, my work could be viewed as the continuation of the previous analysis of \texttt{QUIC}~\cite{overview_of_the_QUIC_protocol}.




% TODO: mention the work of \texttt{QUIC} performance measurements.
% https://dl.acm.org/doi/pdf/10.1145/3242102.3242106



\section{Completed Work}
My analysis shows that a \texttt{QUIC} client can spend around 70\% of CPU time performing cryptographic operations. 
My results are consistent with previous studies that identified cryptographic functions as the current bottleneck of \texttt{QUIC}, e.g.,~\cite{Making_QUIC_Quicker}.






% -------------------------------
% Summary of https://dl.acm.org/doi/pdf/10.1145/3242102.3242106
% "Implementation and Performance Evaluation of the \texttt{QUIC} Protocol in Linux Kernel"

% one of the major points of \texttt{QUIC} is HTTPS <idea taken from Abstract of this paper> -- because HTTPS includes crypto and \texttt{QUIC} can combine the handshakes of both transport and sec layers

% idea of this paper is that the authors implemented \texttt{QUIC} in kernel (not user space, which is a common architectural decision for \texttt{QUIC} but not TCP).
% then, they compared performance of TCP and \texttt{QUIC} when they both ran in kernel space

% The paper links to other performance measurements

% The paper also uses different RTTs and packet loss rates

% The paper used instantaneous throughput to demonstrate the the results!!!

% The paper used 10ms RTT for baseline measurements 

% The paper also discovered that 0.1% packet drop ratio reduced throughput substantially

% The paper also has throughput/(packet-loss-rate) graph
% -------------------------------



% \section{Number of words}
% TODO TO USE

% An approximate word count of the body of the dissertation may be
% obtained using:

% \texttt{wc diss.tex}

% \noindent
% Alternatively, try something like:
% \verb/detex diss.tex | tr -cd '0-9A-Z a-z\n' | wc -w/





\chapter{Preparation}
% ------------------------------------------------
% TODO
%
% Principally, this chapter should describe the work which was undertaken before code was written, hardware built or theories worked on. It should show how the project proposal was further refined and clarified, so that the implementation stage could go smoothly rather than by trial and error.

%Throughout this chapter and indeed the whole dissertation, it is essential to demonstrate that a proper professional approach was employed.

%The nature of this chapter will vary greatly from one dissertation to another but, underlining the professional approach, this chapter will very likely include a section headed "Requirements Analysis" and refer to appropriate software engineering techniques used in the dissertation. The chapter will also cite any new programming languages and systems which had to be learnt and will mention complicated theories or algorithms which required understanding.

%It is essential to declare the starting point. This states any existing codebase or materials that your project builds on. The text here can commonly be identical to the text in your proposal, but it may enlarge on it or report variations. For instance, the true starting point may have turned out to be different from that declared in the proposal and such discrepancies must be explained.



% FROM: https://www.cst.cam.ac.uk/teaching/part-ii/projects/assessment
% Clear motivation, justifying potential benefits of success.
%Good or excellent requirements analysis; justified and documented selection of suitable tools; good engineering approach.
%Clear presentation of challenging background material covering a range of computer science topics beyond Part IB.





% TODO: 1. explain the any background knowledge needed
% TODO: 2. explain the techniques and tools I will use
% TODO: 3. explain the practices I planned to use

% Background knowledge
% Requirements analysis
% > Which techniques and tools coul I use?
% > What did I actually decide to use?
% > Which factors led me to these decisions?
% Methods and Tools
% > what are the engineering practices me project followed?
% > > software -- testing and source control
% > > experiments
% > compare my practices with good engineering practices and explain how/why I decided to do that?

% ------------------------------------------------

In this chapter, I first provide essential background knowledge about the networking landscape before \texttt{QUIC}. 
Then I analyse \texttt{QUIC} protocol in more detail.
Secondly, I present my requirements analysis.
Finally, I describe software engineering tools and techniques used during this project.


\section{Networking Landscape Before \texttt{QUIC}} \label{Networking_Landscape_Before_QUIC}
    \texttt{QUIC} aims to solve some of the design problems present in the \texttt{TCP} protocol. The hope is that improvements in underlying transport layer protocols would improve the application layer protocols' performance.
    In particular, the primary focus is to reduce latency and increase the throughput of the \texttt{HTTP} protocol.
    Hence, it is worth studying previous attempts to improve the performance of HTTP.


\subsection{\texttt{HTTP/1.0} Problems Caused by \texttt{TCP}}
    \texttt{HTTP/1.0} suffers from using one \texttt{TCP} connection for every \texttt{HTTP} request-reply pair \cite{TCP_IP_Guide_Book, HTTP_3_the_past_the_present_and_the_future} --
    opening a new \texttt{TCP} connection for every web object causes \texttt{TCP} to remain in its \enquote{slow start} phase, thus small files are rarely sent at peak throughput~\cite{HTTP_3_the_past_the_present_and_the_future}.
    Furthermore, \texttt{HTTPS} suffers from every request needing to complete both \texttt{TCP} and \texttt{TLS} handshakes that take several round-trip times to complete~\cite{HTTP_3_the_past_the_present_and_the_future}.
    Even though, HTTP/1.0 was a suitable solution for the early days of the Internet when all the HTML files were self-contained~\cite{TCP_IP_Guide_Book_2}, it is not efficient to open and close a new \texttt{TCP} connection for each of the multiple embedded web objects associated with standard websites.

\subsection{Previous Attempt to Improve \texttt{HTTP} by Using \texttt{HTTP/1.1}}

According to the initial draft of \texttt{HTTP/1.1}~\cite{RFC2068}, \texttt{HTTP/1.1} was proposed to mitigate some of the \texttt{HTTP/1.0} problems by introducing persistent connections.
This in turn allows multiple \texttt{HTTP} requests to share the same \texttt{TCP} connection.
Besides being beneficial for small objects, advantage of using a shared \texttt{TCP} connection is that\texttt{TCP} can make better estimates of the actual round-trip time (\texttt{RTT}) between the server and the client~\cite{bib_Computer_Networking_L6}.
More precise \texttt{RTT} measurements allow more consistent utilisation of networking resources.
For example, by evaluating \texttt{TCP} parameters, such as retransmission-timeout, more accurately, the number of unnecessary pre-emptive \texttt{TCP} timeouts can be reduced~\cite{bib_rtt_tcp_Retransmissions}.

Furthermore, \texttt{HTTP/1.1} enables pipelining of multiple \texttt{HTTP} requests over the same \texttt{TCP} connection.
Hence, as stated in~\cite{bib_digital_ocean_http11_vs_http2}, the client does not need to wait for an \texttt{HTTP} reply from the server before sending consecutive \texttt{HTTP} requests.
However, the problem with \texttt{HTTP/1.1} is that \texttt{HTTP} replies need to be sent in order~\cite{RFC7540}. 
So a missing packet of one \texttt{HTTP} request-reply pair could block subsequent \texttt{HTTP} replies~\cite{bib_digital_ocean_http11_vs_http2, head-of-line-blocking-in-quic-and-http-3-the-details}.
In the literature this issue is called Head-of-line blocking (abbreviated HOL).
As Robin Marx wrote, HOL could have a detrimental effect on user experience when sequentially rendering web pages that have dynamically generated content or that contain large embedded objects~\cite{head-of-line-blocking-in-quic-and-http-3-the-details}.



One possible workaround to hide the effect of Head-of-line blocking is to use several shared \texttt{TCP} connections~\cite{bib_digital_ocean_http11_vs_http2}.
In particular, according to Javier Garza~\cite{bib_will-http2-make-my-site-faster}, \texttt{HTTP/1.1} uses six \texttt{TCP} connections.
But, as Timothy Nolan points out~\cite{bib_digital_ocean_http11_vs_http2}, the use of large number of \texttt{TCP} connections is not practical because there is an associated performance overhead of opening and using them.
However, servers also have to share some of the overheads.
For instance, additional \texttt{TCP} connections may require additional memory to store the associated \texttt{TCP} parameters on the server-side~\cite{head-of-line-blocking-in-quic-and-http-3-the-details}.
Finally, application layer Head-of-line blocking problems of \texttt{HTTP/1.1} could be summarised in Figure~\ref{fig:Head_of_line_blocking_of_HTTP1_1}.
This diagram demonstrates that \texttt{HTTP/1.1} fails to address the Head-of-line blocking problem if the server has to transfer more web objects than there are open \texttt{TCP} connections~\cite{head-of-line-blocking-in-quic-and-http-3-the-details}.
For example, the transfer of files 3 and 8 can not be started until the blocking resources (i.e. files 2 and 7) are sent. 

    \begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{figs/Head_of_line_blocking_of_HTTP1_1.png}
    \caption[Head-of-line blocking of \texttt{HTTP/1.1}]{Head-of-line blocking of \texttt{HTTP/1.1}. This diagram visualises the ideas presented in Robin Marx's description of the \texttt{HTTP/1.1} HOL problem~\cite{head-of-line-blocking-in-quic-and-http-3-the-details}}
    \label{fig:Head_of_line_blocking_of_HTTP1_1}
    \end{figure}





\subsection{Previous Attempt to Improve \texttt{HTTP} by Using \texttt{SPDY} and \texttt{HTTP/2.0}} \label{Previous_attempt_to_improve_http_by_using_SPDY_and_HTTP2}
%[TODO describe \texttt{SPDY}]

In order to improve \texttt{HTTP} performance, Google developed a session layer protocol called \texttt{SPDY}~\cite{bib_SPDY_white_paper}.
Then, now obsolete \texttt{SPDY} protocol was used as a blueprint when building the next-generation version of \texttt{HTTP} called \texttt{HTTP/2.0}~\cite{bib_SPDY_vs_HTTP2}.
As Ilya Grigorik states in his book \cite[Chapter~12]{bib_grigorik2013}, the primary achievements of \texttt{HTTP/2.0} are that, compared with \texttt{HTTP/1.1}, \texttt{HTTP/2.0} improves throughput and reduces latency of \texttt{HTTP} protocol by improving utilisation of existing resources.
For example, \texttt{HTTP/2.0} introduced compression of header fields thus reducing communication overhead of \texttt{HTTP} \cite[Chapter~12]{bib_grigorik2013}.
However, the major innovation of \texttt{HTTP/2.0} over \texttt{HTTP/1.1} is that \texttt{HTTP/2.0} improved resource multiplexing \cite[Chapter~12]{bib_grigorik2013}.
Instead of using six \texttt{TCP} connections to hide the problem of Head-of-line blocking, \texttt{HTTP/2.0} uses a single \texttt{TCP} connection~\cite{bib_grigorik2013, head-of-line-blocking-in-quic-and-http-3-the-details}.
As stated in Chapter 12 of Ilya Grigorik's book~\cite{bib_grigorik2013}, to solve the HOL problem in the application level, \texttt{HTTP/2.0} shares the aforementioned single \texttt{TCP} connection over the varying number of streams.
Ideas of \texttt{HTTP/2.0} multiplexing are visualised in Figure~\ref{fig:Multiplexing_HTTP2}.
This diagram demonstrates that logical and independent streams are implemented using frames~\cite{head-of-line-blocking-in-quic-and-http-3-the-details}.
In particular, a single \texttt{TCP} packet may contain several frame headers with their associated payloads~\cite{head-of-line-blocking-in-quic-and-http-3-the-details}.
These \texttt{HTTP/2.0} frame headers allow the protocol to identify different resources and reassemble them independently from each other on the client side.

    \begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figs/Multiplexing_HTTP2.png}
    \caption[Multiplexing of \texttt{HTTP/2.0} using logical streams and frames]{Multiplexing of \texttt{HTTP/2.0} using logical streams and frames. This diagram combines ideas from the Sutandi's Master project about \texttt{QUIC}
   ~\cite{overview_of_the_QUIC_protocol}
    as well as the article written by Robin Marx~\cite{head-of-line-blocking-in-quic-and-http-3-the-details}}
    \label{fig:Multiplexing_HTTP2}
    \end{figure}
    
    
    
    
    


\texttt{HTTP/2.0} solves the initial problem of \texttt{HTTP} Head-of-line blocking, but \texttt{TCP} still suffers from the Head-of-line blocking induced by the \texttt{TCP} itself~\cite{bib_making_web_faster_with_http2, bib_TCP_Head_of_line_blocking_stackoverflow, How-does-HTTP-2-solve-the-Head-of-Line-blocking-HOL-issue, head-of-line-blocking-in-quic-and-http-3-the-details}.
In other words, if a \texttt{TCP} packet containing frames of one stream is lost, then all the remaining \texttt{TCP} packets, containing frames of other streams, can not be delivered to the application layer until the missing packet is not retransmitted~\cite{bib_making_web_faster_with_http2, bib_TCP_Head_of_line_blocking_stackoverflow, How-does-HTTP-2-solve-the-Head-of-Line-blocking-HOL-issue}.
The reason for this is that \texttt{TCP} is a stream-oriented protocol and it guarantees in-order data delivery.
Furthermore, the underlying \texttt{TCP} transport layer is unaware of its byte-stream structure~\cite{head-of-line-blocking-in-quic-and-http-3-the-details}.
As a result, \texttt{TCP} does not try to infer the boundaries of different \texttt{HTTP/2.0} frames~\cite{head-of-line-blocking-in-quic-and-http-3-the-details}.
Hence, in the presence of packet loss, \texttt{TCP} would not deliver to the above layer the correctly-received in-order \texttt{HTTP} frames that were received in the subsequent \texttt{TCP} packets from different logical \texttt{HTTP} streams~\cite{head-of-line-blocking-in-quic-and-http-3-the-details}.
Even correctly delivered \texttt{HTTP} frames would not be delivered until the next correct retransmission of the missing previous \texttt{TCP} packets~\cite{head-of-line-blocking-in-quic-and-http-3-the-details}.
\texttt{TCP} induced Head-of-line blocking has other side effects.
As Gaetano Carlucci et al.~\cite{HTTP_over_UDP_An_Experimental_Investigation_of_QUIC}, the lost \texttt{TCP} packet would reduce the congestion window for all streams multiplexed over the same \texttt{TCP} connection.



% TODO
%[MAYBE TODO: mention Server push functionality]
%[TODO: what is the difference between \texttt{SPDY} and HTTP/2?]


\subsection{Historical Reasons for Invention of \texttt{QUIC}}
As demonstrated in the previous sections, there have already been several attempts to overcome the Head-of-line blocking problems present in \texttt{HTTP}.
In order to finally resolve the HOL blocking problem of \texttt{TCP}, one would need to upgrade this protocol so that \texttt{TCP} could separate frames associated with different logical \texttt{HTTP} streams~\cite{head-of-line-blocking-in-quic-and-http-3-the-details}.
Hence, new version of \texttt{TCP} algorithm would be required. 
However, attempts to roll out experimental versions of \texttt{TCP} to yield benefits to the protocols in the application layer were mostly unsuccessful~\cite{bib_Netdev_0x13_QUIC_Tutorial, PollardBarry2019HiAP}.
For instance, as Craig Andrews states in his article~\cite{the-sad-story-of-tcp-fast-open}, there was a largely unsuccessful proposal called \texttt{TCP Fast Open} to reduce the number of handshakes (and thus round-trip times) required to open \texttt{TCP} connections.
One of the failure factors was related to middleboxes~\cite{the-sad-story-of-tcp-fast-open}.
During the early 2000s, specific architectural problem emerged.
Around that time, the world faced an issue that the Internet was running out of \texttt{IPv4} addresses.
Hence, during that period, middleboxes (e.g. Network Address Translators or NATs for short) gained popularity because it was a temporary and cost-effective solution to the shortage of IP addresses~\cite{MurphyNiallRichard2005Ina, bib_Netdev_0x13_QUIC_Tutorial}.
However, newly introduced middleboxes started to interfere with the \texttt{TCP} traffic~\cite{bib_Netdev_0x13_QUIC_Tutorial, PollardBarry2019HiAP}.
For instance, NATs made assumptions about the structure of \texttt{TCP} headers~\cite{bib_Netdev_0x13_QUIC_Tutorial, PollardBarry2019HiAP}.
As \texttt{TCP/IP} stack was and still is a predominant backbone of the Internet~\cite{tcp-ip-stack_shtml}, some NATs offloaded some \texttt{TCP} processing to hardware or used some software optimisation techniques.
Consequently, these premature optimisations interfered with \texttt{TCP} protocol's correctness -- NATs rejected connections that used experimental \texttt{TCP} packets~\cite{PollardBarry2019HiAP}.
One reason for the slow roll-out of \texttt{TCP} improvements was that \texttt{TCP's} functionality is implemented in the OS kernel.
To add changes to \texttt{TCP}, one would need to change a large number of different operating systems ~\cite{PollardBarry2019HiAP}.
Hence, it was decided that it would be relatively difficult to deploy upgrades for the \texttt{TCP} transport layer protocol~\cite{head-of-line-blocking-in-quic-and-http-3-the-details}.

Architects of \texttt{QUIC} learned these mistakes and attempted to prevent the ossification of \texttt{QUIC} in the future by using several interesting techniques.
To simplify the deployment, \texttt{QUIC's} code operates in user space~\cite{quic-and-http-3-too-big-to-fail}.
In addition, to prevent NATs from interfering with \texttt{QUIC}, \texttt{QUIC's} packet headers are partially encrypted (see subsection \ref{subsection_QUIC_header_format})~\cite{bib_Netdev_0x13_QUIC_Tutorial}.
Finally, instead of upgrading \texttt{TCP} or building a completely new transport layer on top of \texttt{IP}, \texttt{QUIC} builds on top of \texttt{UDP}~\cite{chromium_blog_about_quic}.
The main reason for this is that \texttt{UDP} is an already deployed, supported and recognised transport protocol of the Internet~\cite{the-road-to-quic}.

In conclusion, all these enhancements of \texttt{HTTP} can be summarised in the following historical timeline (see Figure~\ref{fig:cf-secure-web-timeline}).
% TODO: reduce the size of this diagram and take only the most important developments
    \begin{figure}[H]
    \centering
    % \includegraphics[width=0.7\textwidth]{figs/cf-secure-web-timeline-1.png}
    



\begin{tikzpicture}[
roundnode/.style={circle, draw=red!60, fill=red!5, very thick, minimum size=1mm},
squarednode/.style={rectangle, draw=red!60, fill=red!5, very thick, minimum size=5mm},
orangeroundnode/.style={circle, draw=orange!60, fill=orange!5, very thick, minimum size=1mm},
orangesquarednode/.style={rectangle, draw=orange!60, fill=orange!5, very thick, minimum size=5mm},
]
%Nodes
\node[roundnode]    at (0,16)      (start_http09)              [] {};
\node[squarednode]  at (14,16)     (end_http09)                [] {HTTP/0.9};

\node[roundnode]    at (1,15)      (start_http10)              [] {};
\node[squarednode]  at (14,15)     (end_http10)                [] {HTTP/1.0};

\node[roundnode]    at (2,14)      (start_http11)              [] {};
\node[squarednode]  at (14,14)     (end_http11)                [] {HTTP/1.1};

\node[roundnode]    at (3,13)      (start_spdyv1)              [] {};
\node[squarednode]  at (14,13)     (end_spdyv1)                [] {SPDY v1};

\node[roundnode]    at (4,12)      (start_spdyv2)              [] {};
\node[squarednode]  at (14,12)     (end_spdyv2)                [] {SPDY v2};

\node[roundnode]    at (5,11)      (start_quicrypto)              [] {};
\node[squarednode]  at (14,11)     (end_quicrypto)                [] {QUIC crypto};

\node[roundnode]    at (6,10)      (start_gquic)              [] {};
\node[squarednode]  at (14,10)     (end_gquic)                [] {gQUIC};

\node[roundnode]    at (7,9)      (start_ietfquic)              [] {};
\node[squarednode]  at (14,9)     (end_ietfquic)                [] {QUIC IETF};

\node[roundnode]    at (8,8)      (start_http3)              [] {};
\node[squarednode]  at (14,8)     (end_http3)                [] {HTTP/3};

\node[roundnode]    at (9,7)      (start_spdyv3)              [] {};
\node[squarednode]  at (14,7)     (end_spdyv3)                [] {SPDY v3};

\node[roundnode]    at (10,6)     (start_spdyv31)              [] {};
\node[squarednode]  at (14,6)     (end_spdyv31)                [] {SPDY v3.1};

\node[orangeroundnode]    at (0,5)      (start_ssl20)              [] {};
\node[orangesquarednode]  at (14,5)     (end_ssl20)                [] {SSL 2.0 (unsecure \cite{tls-external-facing-services})};

\node[orangeroundnode]    at (1,4)      (start_ssl30)              [] {};
\node[orangesquarednode]  at (14,4)     (end_ssl30)                [] {SSL 3.0 (unsecure \cite{tls-external-facing-services})};

\node[orangeroundnode]    at (2,3)      (start_tls11)              [] {};
\node[orangesquarednode]  at (14,3)     (end_tls11)                [] {TLS 1.1};

\node[orangeroundnode]    at (3,2)      (start_tls12)              [] {};
\node[orangesquarednode]  at (14,2)     (end_tls12)                [] {TLS 1.2};

\node[orangeroundnode]    at (4,1)      (start_tls13)              [] {};
\node[orangesquarednode]  at (14,1)     (end_tls13)                [] {TLS 1.3};



% \node[squarednode]      (http09_start)                              {HTTP/0.9};
% \node[squarednode]      (http09_end)        [right=of http09_start] {HTTP/0.9};
% \node[roundnode]        (lowercircle)       [below=of http09_start] {4};

% %Lines
\draw[->] (start_http09.east) -- (end_http09.west);
\draw[->] (start_http10.east) -- (end_http10.west);
\draw[->] (start_http11.east) -- (end_http11.west);
\draw[->] (start_spdyv1.east) -- (end_spdyv1.west);
\draw[->] (start_spdyv2.east) -- (end_spdyv2.west);
\draw[->] (start_quicrypto.east) -- (end_quicrypto.west);
\draw[->] (start_gquic.east) -- (end_gquic.west);
\draw[->] (start_ietfquic.east) -- (end_ietfquic.west);
\draw[->] (start_http3.east) -- (end_http3.west);
\draw[->] (start_spdyv3.east) -- (end_spdyv3.west);
\draw[->] (start_spdyv31.east) -- (end_spdyv31.west);

\draw[->] (start_ssl20.east) -- (end_ssl20.west);
\draw[->] (start_ssl30.east) -- (end_ssl30.west);
\draw[->] (start_tls11.east) -- (end_tls11.west);
\draw[->] (start_tls12.east) -- (end_tls12.west);
\draw[->] (start_tls13.east) -- (end_tls13.west);


\draw[->] (start_http09.east) .. controls +(right:5mm) and +(up:5mm) .. (start_http10.north);
\draw[->] (start_http10.east) .. controls +(right:5mm) and +(up:5mm) .. (start_http11.north);
\draw[->] (start_http11.east) .. controls +(right:5mm) and +(up:5mm) .. (start_spdyv1.north);
\draw[->] (start_spdyv1.east) .. controls +(right:5mm) and +(up:5mm) .. (start_spdyv2.north);
\draw[->] (start_spdyv2.east) .. controls +(right:5mm) and +(up:5mm) .. (start_quicrypto.north);
\draw[->] (start_quicrypto.east) .. controls +(right:5mm) and +(up:5mm) .. (start_gquic.north);
\draw[->] (start_gquic.east) .. controls +(right:5mm) and +(up:5mm) .. (start_ietfquic.north);
\draw[->] (start_ietfquic.east) .. controls +(right:5mm) and +(up:5mm) .. (start_http3.north);
\draw[->] (start_http3.east) .. controls +(right:5mm) and +(up:5mm) .. (start_http3.north);
\draw[->] (start_http3.east) .. controls +(right:5mm) and +(up:5mm) .. (start_spdyv3.north);
\draw[->] (start_spdyv3.east) .. controls +(right:5mm) and +(up:5mm) .. (start_spdyv31.north);


\draw[->] (start_ssl20.east) .. controls +(right:5mm) and +(up:5mm) .. (start_ssl30.north);
\draw[->] (start_ssl30.east) .. controls +(right:5mm) and +(up:5mm) .. (start_tls11.north);
\draw[->] (start_tls11.east) .. controls +(right:5mm) and +(up:5mm) .. (start_tls12.north);
\draw[->] (start_tls12.east) .. controls +(right:5mm) and +(up:5mm) .. (start_tls13.north);

    \draw [-stealth](0,0)  -- (15,0) node[midway, above] {Time};
    
\end{tikzpicture}

\caption[Evolution timeline of the related network technologies]{Evolution timeline of the related network technologies. This diagram is taken from \texttt{Cloudflare}'s blog~\cite{http-3-from-root-to-tip}.}
    \label{fig:cf-secure-web-timeline}
    \end{figure}


\section{\texttt{QUIC} Details} \label{QUIC_details_section}

\texttt{QUIC} is a next-generation transport layer protocol whose network stack is demonstrated in Figure~\ref{fig:QUIC_network_stack}. In this diagram, the \texttt{UDP} transport layer protocol is smaller than the \texttt{TCP} layer because \texttt{UDP} only provides multiplexing between the two processes of the two end hosts by using port numbers~\cite[Chapter 5.1]{PetersonLarryL2007CNAS}.
\texttt{UDP} sends packets in \enquote{fire and forget} manner~\cite{Google_QUIC_protocol_moving_the_web_from_TCP_to_UDP}.
Hence, \texttt{UDP} does not guarantee reliable packet delivery, and it does not provide congestion control~\cite[Chapter 5.1]{PetersonLarryL2007CNAS}.
However, \texttt{UDP} checksum adds a mechanism to verify that \texttt{UDP} packets are valid and arrive at the intended recipients
\cite[Chapter 5.1]{PetersonLarryL2007CNAS}, \cite{how-is-tcp-and-udp-checksum-calculated, udp-user-datagram-protocol}.

\simon{Isn't UDP checksum used for a partial error detection?
If that is NOT the case, then remove the previous sentence.}

% [TODO: WHAT end-to-end LATENCY?]
\texttt{TLS1.3} layer in Figure~\ref{fig:QUIC_network_stack} is shown as being part of the \texttt{QUIC} protocol because, as I have already mentioned in \S~\ref{Networking_Landscape_Before_QUIC},  \texttt{QUIC} aims to reduce end-to-end latency by combining handshakes of both transport (\texttt{QUIC}) and security (\texttt{TLS1.3}) layers~\cite{Google_QUIC_protocol_moving_the_web_from_TCP_to_UDP, HTTP_3_the_past_the_present_and_the_future}.

Finally, \texttt{QUIC} requires a completely new application layer protocol, called \texttt{HTTP/3}, that is only compatible with \texttt{QUIC}~\cite{head-of-line-blocking-in-quic-and-http-3-the-details}.
For completeness I will mention that \texttt{HTTP/3} layer is smaller than analogous \texttt{HTTP/2} layer because some tasks usually associated with the application layer (e.g., stream multiplexing and connection management) are delegated to \texttt{QUIC}~\cite{bib_grigorik2013}, \cite[Chapter 12]{Google_QUIC_protocol_moving_the_web_from_TCP_to_UDP}.


% TODO - combine these ideas to explain the smaller HTTP3
% because \enquote{(...) data across streams is no longer fully  ordered}~\cite{head-of-line-blocking-in-quic-and-http-3-the-details}.
% TODO: what does it mean for QUIC streams not to be ordered

    \begin{figure}[ht]
    \centering
    \includegraphics[width=0.9\textwidth]{figs/Layers_in_the_protocol_stack.png}
    \caption[\texttt{QUIC/UDP/IP} network stack compared to \texttt{TCP/IP} network stack]{\texttt{QUIC/UDP/IP} network stack compared to \texttt{TCP/IP} network stack. This diagram combines ideas of Robin Marx's presentation about \texttt{QUIC}~\cite{head-of-line-blocking-in-quic-and-http-3-the-details} as well as other sources \cite{overview_of_the_QUIC_protocol, IETF_presentation_about_QUIC, HTTP_3_the_past_the_present_and_the_future}.
    }
    \label{fig:QUIC_network_stack}
    \end{figure}



% ------------------------------
% TODO: maybe incorporate the paragraph below:
%
% As Mattias Geniar wrote in Chapter 12~\cite{Google_QUIC_protocol_moving_the_web_from_TCP_to_UDP}, \texttt{HTTP over QUIC} layer (which is now called \texttt{HTTP/3}~\cite{HTTP_3_the_past_the_present_and_the_future}) is smaller than analogous \texttt{HTTP/2} layer because stream multiplexing and connection management tasks are delegated to \texttt{QUIC}~\cite{bib_grigorik2013}.
% ------------------------------


As demonstrated in Figure~\ref{fig:IP_UDP_QUIC_packets}, \texttt{QUIC} packets are encapsulated inside \texttt{UDP} packets which in turn are sent using \texttt{IP} packets.


    \begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{figs/IP_UDP_QUIC packets.png}
    \caption[The relative packet structure of \texttt{IP/UDP/QUIC} network stack]{The relative packet structure of \texttt{IP/UDP/QUIC} network stack. This diagram is drawn from the latest \texttt{IETF}'s description of \texttt{QUIC}~\cite{ietf-quic-transport-34}}
    \label{fig:IP_UDP_QUIC_packets}
    \end{figure}
    
\simon{Figure~\ref{fig:IP_UDP_QUIC_packets} could be removed if there is a lack of space}



An example of \enquote{real-life} \texttt{QUIC} packets, captured using \texttt{Wireshark} network analysis tool, is shown in Figure~\ref{fig:Wireshark_screenshot}.



\simon{MAYBE TODO: describe UDP/QUIC packets and their field values}


\subsection{\texttt{QUIC} Features}
% https://archive.nanog.org/sites/default/files/meetings/NANOG64/1051/20150603_Rogan_Quic_Next_Generation_v1.pdf
% TODO: read https://tools.ietf.org/html/draft-ietf-quic-transport-32#section-1
% TODO: read https://arxiv.org/pdf/1801.05168.pdf
\begin{itemize}


 \item \textbf{Connection migration} 
 % (https://peering.google.com/\#/learn-more/quic, https://ma.ttias.be/googles-quic-protocol-moving-web-tcp-udp/)
 
    % As I have already mentioned in the Introduction section, more than 90\% of all Internet users use mobile devices to connect to the Internet~\cite{bib_number_of_mobile_users}.
    Nowadays ubiquitous mobile devices~\cite{bib_number_of_mobile_users} can change their location, and thus their Internet access can change frequently too~\cite{PollardBarry2019HiAP}.
    This is particularly problematic for \texttt{TCP} because \texttt{TCP's} connection is tied to a particular \texttt{IP} address~\cite{PollardBarry2019HiAP}.
    As a result, \texttt{TCP} needs to establish a new connection every time the network Wi-Fi network is changed~\cite{PollardBarry2019HiAP}.
    This means that frequent access point changes would hurt \texttt{TCP's} performance because \texttt{TCP} would have to spend more time in the \enquote{slow-start} phase and perform additional handshakes.
    In addition, because of the different signal paths, other access points may have distinct round-trip times.
    Hence, after changing its access point, the mobile device may incorrectly use RTT estimates from the previous Wi-Fi connection for the congestion control over the new access point.
    These example demonstrates that \texttt{TCP} protocol assumes that \texttt{IP} address would not frequently change~\cite{PollardBarry2019HiAP}.
    In contrast, \texttt{QUIC} is more suitable to handle connections via mobile devices.
    In particular, \texttt{QUIC} has an explicit connection ID that does not depend on the IP address~\cite{PollardBarry2019HiAP}.
    Hence, \texttt{QUIC} clients can migrate between multiple different \texttt{IP} networks without having to re-establish a \texttt{QUIC} connection.
    
    
    





\item \textbf{Fast \texttt{TLS1.3} handshake}

As shown in Figure~\ref{fig:QUIC_handshake_vs_TCP-TLS_handshake}, one of the core innovations of \texttt{QUIC} is to combine the transport and security layer handshakes thus reducing latency of the first \texttt{HTTP} request.


     \begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{figs/QUIC_handshake_vs_TCP-TLS_handshake.png}
    \caption[Comparison of handshakes required to issue an \texttt{HTTP} request]{Comparison of handshakes required to issue an \texttt{HTTP} request. The left section demonstrates that traditionally multiple round trip times are required to establish a connection to issue an \texttt{HTTP} request. The right section of the diagram shows that \texttt{QUIC}, on the other hand, combines transport and security layer handshakes. This diagram is a reproduction of the similar diagram taken from~\cite{the-road-to-quic}.}
    \label{fig:QUIC_handshake_vs_TCP-TLS_handshake}
    \end{figure}
 
 % TODO: Why do we need a TCP handshake?
 % TODO: why do we need a TLS handshake?
 % TODO: what info is sent in \texttt{QUIC} handshake?
 % MAYBE TODO: mention possible amplification attacks of \texttt{QUIC} (https://blog.cloudflare.com/the-road-to-quic/) 
 



  \item 
    According to the \texttt{IETF QUIC} draft, Section 1~\cite{ietf-quic-transport-draft}, \texttt{QUIC} offers \textbf{zero round-trip-time connections} (abbreviated \texttt{0-RTT}) provided that the server and client had an established connection in the recent past~\cite{introducing-0-rtt}.
    In other words, under the aforementioned circumstances, \texttt{QUIC} server and client can start exchanging data without having to wait for the completion of the new handshake~\cite{ietf-quic-transport-draft}.
  
  

  \item 
  An interesting design choice of \texttt{QUIC} is that it is \textbf{implemented in user space rather than kernel space}~\cite{the-road-to-quic, Implementation_and_Performance_Evaluation_of_the_QUIC_Protocol_in_Linux_Kernel}.
  The major advantage of this approach is that new versions of \texttt{QUIC}, associated with user-level programs, can be quickly deployed (e.g. by deploying protocol updates with the software updates)~\cite{the-road-to-quic}.
  In addition, despite several exceptions such as Google, Microsoft, and Apple, operating systems may not be controlled by the same companies as the ones that develop client-side software, such as browsers~\cite{2016-12-01-quic-tou}.
  Hence, there are additional incentives for the companies developing \texttt{QUIC} to deploy this protocol in user space.
  However, there is an associated cost of the user space because data has to be copied from kernel space to user space~\cite{benchmarking-quic}.
  
  
 
  \item \texttt{QUIC} features include packet \enquote{\textbf{encryption by default}}~\cite{the-road-to-quic}.
  Moreover, there are no implementations of \texttt{QUIC} without embedded security layer~\cite{head-of-line-blocking-in-quic-and-http-3-the-details}.
  However, there is some criticism that Internet Service Providers could be having problems in the future managing encrypted, and thus non-transparent, \texttt{QUIC} traffic inside their networks~\cite{why-is-googles-quic-leaving-network-operators-in-the-dark}.
  The concern is that conventional wirewalls would not be able to reject suspicious \texttt{QUIC} packets.
  


  \item 
    \texttt{QUIC} also provides \textbf{reliable in-order data delivery}~\cite[Section 7]{ietf-quic-transport-draft}, ~\cite{head-of-line-blocking-in-quic-and-http-3-the-details} .
    The main purpose of this is to replace \texttt{TCP} by offering identical or better guarantees. 
    Similarly, \texttt{QUIC} implements \textbf{congestion control} because, as I have already mentioned in the previous sections, the underlying transport protocol layer \texttt{UDP} does not provide this mechanism. 
  
  
  In order to understand subsequent features of \texttt{QUIC} we need some background knowledge about its flow control.
  % TODO
  [TODO: add information about streams]
  %  Multiple streams & frames
  
  
  % ----------------------
  
  
  \item TODO loss recovery
  % Loss detection: https://quicwg.org/base-drafts/draft-ietf-quic-recovery.html#name-loss-detection
  % > packet-number based approach with a timer

  \item TODO multiplexed streams
 
  \item TODO loss detection with signaling (using new seq number)
  
  
  
  
  
\end{itemize}


\subsection{Advantages of \texttt{QUIC}} \label{QUIC_advantages}

\begin{itemize}
  \item Reduced latency:
  According to [https://blog.chromium.org/2015/04/a-quic-update-on-googles-experimental.html]: "$<\ldots>$ \texttt{QUIC} outshines TCP under poor network conditions, shaving a full second off the Google Search page load time for the slowest 1\% of connections".

  % TODO: read https://blog.cloudflare.com/introducing-0-rtt/
  
  \item TODO include https://blog.cloudflare.com/http-3-vs-http-2/
\end{itemize}




\subsection{\texttt{QUIC}'s Header Format} \label{subsection_QUIC_header_format}

\begin{itemize}
  \item TODO mention that the packet header encryption is separate from payload encryption
  \item TODO explain why do we need this separation
  \item TODO present long and short headers give a list of fields
  \item TODO mention that packet numbers are encrypted, but connection ID is not
\end{itemize}

\subsection{\texttt{QUIC}'s Adoption}

At the time of writing, $5.0\%$ of all the websites on the Internet used \texttt{QUIC} and $14.5\%$ used \texttt{HTTP/3}~\cite{bib_Adoption_comparison_Between_http2_http3_quic}.
Similarly, according to Cloudflare\footnote{https://radar.cloudflare.com/}, at the same time 11\% of traffic used \texttt{HTTP/3}.



\section{Implementations of QUIC} \label{List_of_QUIC_implementations}
According to \texttt{QUIC} Working Group~\cite{number_of_QUIC_implementations}, there is 31 different implementation of QUIC. Most of the implementations, 22 to be precise, are written using C/C\texttt{++} language family (e.g., \texttt{Chromium}\footnote{https://chromium.googlesource.com/chromium/src/net/+/master/quic/}) while the remaining implementations use Rust (e.g., \texttt{quiche}\footnote{https://github.com/cloudflare/quiche}), Python (e.g., \texttt{aioquic}\footnote{https://github.com/aiortc/aioquic}), Haskel (e.g., \texttt{Haskell quic}\footnote{https://github.com/kazu-yamamoto/quic}), Java (e.g., \texttt{kwik}\footnote{https://bitbucket.org/pjtr/kwik/src/master/}), Go (e.g., \texttt{quic-go}\footnote{https://github.com/lucas-clemente/quic-go}) or JavaScript (e.g., \texttt{Node.js QUIC}\footnote{https://github.com/nodejs/quic}).


\subsection{Why are there so many Implementations of QUIC?}

\texttt{QUIC} is implemented in the user space~\cite{quic-and-http-3-too-big-to-fail}.
Hence, this flexibility simplifies the development and deployment of the new \texttt{QUIC} implementations.
In addition, all the major Operating Systems, e.g., Microsoft Windows~\cite{OS_implementations}, Linux~\cite{OS_implementations, linux_kernel_programming_language}, iOS~\cite{OS_implementations, IOKitFundamentals}, are written in C language family.
There are numerous bootstrapping compilers written in C, meaning that any user level program, potentially written in different programming language, can be compiled and run.
However, there is an associated cost of using protocol in user space. 
Langley et. al. found that \texttt{YouTube's} servers used 350\% more \texttt{CPU} resources when delivering content via \texttt{QUIC} connections as opposed to using \texttt{TCP} with \texttt{TLS}~\cite{QUIC_SERVER_REQUIRES_3-5_more_CPU_resources}.
In addition, by deploying \texttt{QUIC} changes in the user space, companies can also patch proprietary extensions.
Firms can even use their market dominance (e.g., in the browser industry) to enforce these protocol updates.
However, there is no guarantee that proprietary extensions would improve network connections for the general public. 

\subsection{Selecting  \texttt{ngtcp2}}
%TODO: fix style and grammar:
There are many implementations of \texttt{QUIC} (see subsection \ref{List_of_QUIC_implementations}) written in different languages.
I considered  \texttt{aioquic}\footnote{https://github.com/aiortc/aioquic},  \texttt{MsQuic}\footnote{https://github.com/microsoft/msquic},  \texttt{ngtcp2}\footnote{https://github.com/ngtcp2/ngtcp2},  \texttt{mvfst}\footnote{https://github.com/facebookincubator/mvfst} and \texttt{Quant}\footnote{https://github.com/NTAP/quant}.
Before changing the direction of the dissertation, one of the primary goals of the project was to turn off header encryption of \texttt{QUIC} packets so that I could inspect these packets in hardware.
Hence, I performed a survey to find \texttt{QUIC} implementation, which had an API to control encryption. 
\texttt{Aioquic}, \texttt{MsQuic} and \texttt{ngtcp2} seemed to be the most promising.
However, despite being a simple and well-documented implementation of \texttt{QUIC}, \texttt{aioquic} did not have an active development team that could answer technical questions.
Similarly, \texttt{MsQuic} seemed promising, but some of the performance measurement tools used by the \texttt{MsQuic} team were proprietary and not yet released to the public. 
I thought that in this dissertation it would be wise to use similar testing conditions as the ones used in the previous similar paper (Yang et al.~\cite{Making_QUIC_Quicker}).
In particular, the authors of this paper evaluated several  or C\texttt{++} \texttt{QUIC} implementations.
Hence, I decided to follow a similar approach, and I picked \texttt{ngtcp2}, written in C.
I identified the experimental \texttt{QUIC} benchmarking tool called \texttt{h2load}\footnote{https://github.com/nghttp2/nghttp2/tree/quic}, which is compatible with \texttt{ngtcp2}.
Moreover, \texttt{h2load} is written by Mr Tatsuhiro  Tsujikawa (a co-author of \texttt{ngtcp2}).
Both \texttt{h2load} and \texttt{ngtcp2} use similar library functions meaning that I could deploy software updates to both programs with minimal effort.

\section{Requirements Analysis}

% TODO
\simon{
1. Which techniques and tools could I use?
\begin{itemize}
  \item Network simulation tools:
      \begin{itemize}
      \item I could have used localhost (adv: simple, disadv: artificial and cant use NICs that add extra pecularities (No offloading))
        
     \item I could have excluded the intermediate machine - meaning that I could have forced packets to leave the testing machine but send them via loopback to the same machine on different interface. (adv/disadv: more complex than the previous approach, but still relatively, adv: can inspect behaviour of NICs; disadv: traffic perturbations are added on the testing machine - extra burden; disadv: Network Emulation could have interfered with the analysis of QUIC. For instance, what packet arrival time should be used when packet enters an interface? - netem adds extra complexity here and these measurements might not be very accurate)
        
     \item Use a separate dedicated machine to introduce traffic perturbations
        \begin{itemize}
        \item Adv: replicate similar conditions as the ones used in Gianni's paper
        
        
        \item Adv: Leave network emulation tasks to the intermediate machine - now intermediate machine can be optimised for responsiveness and the testing machine could be optimised for generating and receiving QUIC traffic
        
        \item Disadv: the most complex, requires additional computer, forwarding and separate subnets
        \end{itemize}
      \end{itemize}
  
  
    \item Could have used Mininet and a pair of Virtual machines (but I already had required hardware and I wanted to make comparable tests with Gianni's paper)
\end{itemize}
}


\simon{
2. What did I actually decide to use?

I used localhost connection for quick prototyping.

Then, I used loopback cables to quickly test whether or not packets leave the machine (I ran experiments on the testing machine and check if unplugging network cable would stop the data transfer)

However, my major testing configuration used the configuration with an intermediate machine - I used this configuration because I managed to configure different subnets and enabled packet forwarding.
}

\simon{3. Which factors led me to these decisions?


The main reason for deciding on this architecture was correct configuration of netem - using a separate machine for Network emulation I was sure that packet arrival and departure times don't interfere with Netem - (e.g. don't want to say that the packet has arrived before it is droped/delayed in the Netem).



In addition, this experiment setup would not be possible without the prio possession of the required hardware (i.e., additional machine). 
}

\simon{TodO: also, mention that I measured an overhead of NetEm and intermediate machine and it was negligible [TODO: bring those numbers here]}


\section{Starting Point}
As mentioned in the previous sections, this project builds on top of \texttt{ngtcp2} implementation of \texttt{QUIC}.
In other words, relevant networking stack tools such as cryptographic library (e.g. \texttt{OpenSSL}), benchmarking tool (e.g. \texttt{h2load}), custom \texttt{HTTP} layers (e.g. \texttt{nghttp2} and \texttt{ngtcp3}) have already been built and integrated. 
Moreover, in this project I used inspiration from Yang et al.~\cite{Making_QUIC_Quicker} when configuring the testing environment of \texttt{QUIC}.
In particular, I replicated their physical and architectural layout of components required to simulate different conditions of the network (see section \ref{physical_setup_subsection}).

The concepts of \texttt{QUIC} were introduced in the Part IB \enquote{Computer Networking} and Part II \enquote{Principles of Communications} courses.
In addition, fundamentals of C and C\texttt{++} were covered in \enquote{Programming in C and C\texttt{++}} course. 
Besides that, I used C\texttt{++} in my summer internship.

Throughout the project, the focus of the dissertation changed from hardware to software.
Hence, hardware offloading oriented code (e.g. \texttt{NetFPGA} codebase) and tools (e.g. \texttt{Xilinx/Vivado} tools for programming with FPGAs) used at the beginning of the project had little utility for the remaining part of the dissertation.
In addition, I did not end up using the high-speed network emulator called \texttt{TLEM}~\cite{TLEM_tool} because the existing network emulation tool called \texttt{NetEm} did not seem to add a noticeable performance overhead for the selected testing workloads.


\section{Software Engineering Techniques and Tools}
    To track the code changes, I used \texttt{Git} source control tool.
    In particular, I used \texttt{GitHub} to store forked repositories of \texttt{ngtcp2}, \texttt{openssl}, \texttt{nghttp2} and \texttt{nghttp3}.
    In addition, the dissertation document was written using the online \LaTeX\  editor Overleaf\footnote{\url{https://www.overleaf.com/}} and changes were also committed to a separate repository on \texttt{GitHub}.
    Furthermore, I used different coding environments.
    At first, I worked with \texttt{NetBeans} IDE.
    But as I was extensively analysing existing code written by other programmers (i.e. \texttt{ngtcp2} and its related components), I needed an effective tool to search through the codebase.
    Hence, I opted for \texttt{Visual Studio Code} IDE which also had a convenient tool to compare \texttt{git} changes.
    
    
    Throughout the project, I employed \texttt{Agile} software development practices.
    For instance, for performance evaluation, I had to configure testing machines using repetitive commands but typing these instructions by hand is a laborious and error-prone process.
    As a result, after detecting an error caused by an incorrect configuration, I usually augmented the \texttt{bash} setup script to set missing parameters automatically.
    Furthermore, I had Weekly progress updates with several other Part II students.
    During these virtual \enquote{stand-up meetings} I had an opportunity to reflect on project-related issues.
    To record my daily progress, I used a logbook, stored in the \texttt{Google Docs}.
    Besides that, I used an application called \texttt{Trello}\footnote{\url{https://trello.com/en-GB}} to group, track and re-order subtasks according to their importance (see Figure~\ref{fig:Trello_board}).

    \begin{figure}[ht]
    \centering
    \includegraphics[width=0.9\textwidth]{figs/Trello_board.PNG}
    \caption{\texttt{Trello} board of important tasks}
    \label{fig:Trello_board}
    \end{figure}
    
    During the winter vacation I returned back home so I had made the necessary steps beforehand to be able to have remote access to the specialised hardware.
    In particular, I first enabled permanent remote access to the testing machines using remote desktop access software called \texttt{TeamViewer}\footnote{\url{https://www.teamviewer.com/en/}}.
    It allowed me to access the aforementioned machines outside the college network.
    Then, as shown in Figure~\ref{fig:setup_map}, I added additional redundant backup \texttt{ssh} connections between the testing computers to improve the resilience of the system in case one of the \texttt{TeamViewer} links failed.
    Finally, to further mitigate potential risks, I had two emergency contacts (two non-technical students from the same college) who were granted a permission to enter my room and access the machines inside it in case of an accident.
    This last step turned out to be useful because I was able to ask my fellow students to turn off the testing machines before the college network was shut down for maintenance operations.
    

    \begin{figure}[ht]
    \centering
    \includegraphics[width=0.9\textwidth]{figs/Setup map.png}
    \caption[Contingency plan to work remotely]{Contingency plan to work remotely}
    \label{fig:setup_map}
    \end{figure}

    Besides that, I used different communication channels to discuss configuration and technical issues with other \texttt{QUIC} developers.
    At first, I used \texttt{GitHub} to raise issues.
    Then, I started using a direct messaging application called \texttt{Slack}\footnote{\url{https://slack.com/intl/en-gb/}} 
    and it improved the speed of communications substantially.

    Furthermore, after winter vacation, I brought an additional laptop from home to improve the development speed.
    This computer was used as a sandbox to test different implementations of \texttt{QUIC} before deploying them to the main machines.
    Before then, I had a problem that testing machines had pre-configured software which used incompatible settings with the configuration parameters required for \texttt{QUIC} implementations (e.g. existing software stack used older OS version).
    However, with the help of the additional laptop, I was able to verify the correctness of \texttt{ngtcp2}, a selected implementation of \texttt{QUIC}.
    Besides that, I ensured the correctness of the null encryption of \texttt{ngtcp2} by writing and running several integration tests.
    In particular, these tests check whether or not the received \texttt{HTML} file is identical to the transmitted \texttt{HTML} file.
    
    Finally, for some aspects of the project, I used non-standard practices.
    For example, I ran testing machines with root privileges.
    On the one hand, such a configuration would be insecure for the general computer user. On the other hand, using root privileges by default allowed me to avoid frequent issues with insufficient permissions as I had to run configuration commands which required top-level permissions multiple times.
    
    

\chapter{Implementation}
% ------------------------------------------------
% TODO

%This chapter should describe what was actually produced: the programs which were written, the hardware which was built or the theory which was developed. Any design strategies that looked ahead to the testing stage should be described in order to demonstrate a professional approach was taken.

%Descriptions of programs may include fragments of high-level code but large chunks of code are usually best left to appendices or omitted altogether. Analogous advice applies to circuit diagrams or detailed steps in a machine-checked proof.

%The implementation chapter should include a section labelled "Repository Overview". The repository overview should be around one page in length and should describe the high-level structure of the source code found in your source code repository. It should describe whether the code was written from scratch or if it built on an existing project or tutorial. Making effective use of powerful tools and pre-existing code is often laudable, and will count to your credit if properly reported. Nevertheless, as in the rest of the dissertation, it is essential to draw attention to the parts of the work which are not your own. 

%It should not be necessary to give a day-by-day account of the progress of the work but major milestones may sometimes be highlighted with advantage.


% FROM: https://www.cst.cam.ac.uk/teaching/part-ii/projects/assessment
%Contribution to the field.
%Application of extra-curricular reading and original interpretation of previous work from academia or industry.
%Challenging goals and substantial deliverables with excellent selection and application of appropriate mathematical, scientific and/or engineering techniques.
%Clear and justified repository overview.
%At most minor faults in execution or understanding.
% ------------------------------------------------


In this chapter I first give an overview of the repository structure.


\section{Repository Overview} 
% TODO
\simon{TODO add reference to the original page of ngtcp2}
First of all, I added support of null encryption in the cloned repository of \texttt{ngtcp2}.

In addition, I augmented \enquote{README} file of the primary repository with specific instructions on how to compile and run the software stack required for this project.

% TODO
\simon{TODO: mention that I forked part of networking stack required to run ngtcp2. In particular, I worked on a separate openssl(embeded security layer), ngtcp2 (transport layer), nghttp2 and nghttp3 (application layers) }

\section{Preparation Scripts}
As I have already mentioned, I wrote several scripts to prepare testing machines for performance analysis.
These commands are stored in \texttt{\textasciitilde/.zshrc} and \texttt{\textasciitilde/.bashrc} files (see Appendix~\ref{preparation_script_from_zshrc}) meaning that preparation scripts are executed every time a new terminal is opened.


 % TODO mention ping test
 % TODO state that it configures virtual namespaces to separate server from client
 % TODO add scripts to appendix

The automatic preparation scripts improved development speed because certain repetitive tasks were automated.
Furthermore, the setup of the testing environment became more predictable, meaning that performance tests generated more reproducible results.



\section{Using Null Encryption}
% TODO
\simon{TODO add reference saying that encryption of \texttt{QUIC} is turned on by default}

By design, \texttt{QUIC} uses encryption by default.
It encrypts both the payloads of the packets and some fields in the packet headers.


However, encryption and decryption operations were found to be computationally expensive.
% TODO
\simon{TODO add a reference showing that \texttt{QUIC} crypto functions are expensive}

These intensive operations could have become a performance bottleneck of QUIC.
To validate this claim, I had to measure the impact of cryptographic operations on QUIC's performance by comparing the throughput between the two server-client pairs.
One pair had to use standard encryption and decryption procedures, while another had to exchange unencrypted packets.
I achieved this by implementing logic that can turn on null encryption on \texttt{ngtcp2}.
% TODO
\simon{TODO add a link to null encryption}

In essence, null encryption is a technique that effectively turns off encryption by encrypting/decrypting the data by ``XOR"ing the data with a key made entirely of zeroes (which leaves the data unchanged). 

% TODO
\simon{TODO -- say which cryptographic operations are performed and which ones are omitted when using my implementation of null-crypto}


% TODO
\simon{TODO: mention improved null encryption}

% TODO
\simon{TODO: mention that I later on found existing null encryption and decryption mechanisms in the unit tests of \texttt{ngtcp2}. 
However, my implementation was developed independently and without knowledge about the existence of these functions.
This can be proven by my commit history and communication history on the \texttt{Slack} messaging platform.
Furthermore, the performance analysis I described before allowed me to identify potential bottlenecks of my implementation.
Hence, I was able to improve my null cryptographic operations in a systematic way.}





My implementation of null encryption has room for improvements.
For instance, every encrypted \texttt{ngtcp2} packet uses additional 16 bytes to store the encryption header.
However, in the null-encryption scenario, these additional fields are not required, but my implementation of disabling encryption does not use them, meaning that 16 unused bytes are transferred in a single \texttt{QUIC} packet.
In contrast, \texttt{MsQuic} does have a mechanism allowing unencrypted \texttt{QUIC} packets to re-use these additional 16 bytes for data transfer.



\section{Testing Scripts}

In order to measure the performance of the \texttt{QUIC} protocol, I am running several automated scripts on the testing computer (see Figure~\ref{fig:Physical_testing_environment}).
In particular, I am using Python and/or Bash scripts to configure the testing environment and initiate the \texttt{QUIC} server-client pair.
In addition, to control the networking conditions of the simulated network the scripts on the testing machine use \texttt{ssh} (abbreviation of Secure Shell Protocol) connection to control the intermediate machine.
Later on, Python scripts save, aggregate and visualise the results of the experiments.
The use of scripting languages, in this case, is acceptable because performance measurements require quick prototyping.
Furthermore, code maintainability is not the major design goal of this project.






\chapter{Evaluation}
% ------------------------------------------------
%This is where Assessors will be looking for signs of success and for evidence of thorough and systematic evaluation. Sample output, tables of timings and photographs of workstation screens, oscilloscope traces or circuit boards may be included. Care should be employed to take a professional approach throughout. For example, a graph that does not indicate confidence intervals will generally leave a professional scientist with a negative impression. As with code, voluminous examples of sample output are usually best left to appendices or omitted altogether.

%There are some obvious questions which this chapter will address. How many of the original goals were achieved? Were they proved to have been achieved? Did the program, hardware, or theory really work?

%Assessors are well aware that large programs will very likely include some residual bugs. It should always be possible to demonstrate that a program works in simple cases and it is instructive to demonstrate how close it is to working in a really ambitious case.
% ------------------------------------------------



\section{Setup}

As this project builds on the ideas presented in~\cite{Making_QUIC_Quicker}, I thought that it would be reasonable to replicate a similar testing environment to obtain comparable results.

\subsection{Logical Setup}
To test a simple single flow performance, it is sufficient to have a single \texttt{QUIC} server-client pair, as depicted in Figure~\ref{fig:Logical_testing_environment}.
To measure \texttt{QUIC} performance under different conditions, we need to add a network emulator between the \texttt{QUIC} client and the \texttt{QUIC} server.

    \begin{figure}[ht]
    \centering
    \includegraphics[width=0.9\textwidth]{figs/Logical_testing_environment.png}
    \caption{Logical configuration of testing environment}
    \label{fig:Logical_testing_environment}
    \end{figure}

\subsection{Physical Setup} \label{physical_setup_subsection}

\simon{Specify software and hardware parameters of the testing environment as shown in \url{https://github.com/Shenggan/quic_vs_tcp} }

\simon{TODO: add information about the capacities of Ethernet links}


    In the ideal scenario, we might want to use three dedicated machines for performance measurements, as shown in the previous section.
    However, I decided to use a slightly different physical layout (see Figure~\ref{fig:Physical_testing_environment}).
    In this environment, one machine (A) hosts client-server pair, while another computer (B) acts as a network emulator.
    The physical configuration differs from the logical configuration because I wanted to replicate testing conditions under which Yang et al. performed throughput measurements of \texttt{QUIC}~\cite{Making_QUIC_Quicker}.
    One advantage of having both server and client running on the same machine is that the shared system clock can perform measurements more accurately. 
    

    \begin{figure}[ht]
    \centering
    \includegraphics[width=0.9\textwidth]{figs/Physical_testing_environment.png}
    \caption[Physical configuration of testing environment]{Physical configuration of testing environment. This scheme is an adaptation of the configuration environment used in ~\cite{Making_QUIC_Quicker}}
    \label{fig:Physical_testing_environment}
    \end{figure}
    
    As we can see from Figure~\ref{fig:Physical_testing_environment}, both \texttt{QUIC} client and server operate on different virtual network namespaces which do not have shared point-to-point links.
    Client and server are assigned different network subnets.
    An intermediate machine (B) is configured as the default gateway for both virtual network namespaces.
    As a result, all the packets between the \texttt{QUIC} server and client have to travel via an intermediate machine (B).
    Here, depending on the experiment, network perturbations (e.g. packet loss, delay, reordering) may be introduced.
    In particular, to simulate different networking conditions I used \texttt{NetEm} tool (abbreviation of \enquote{Network Emulator})\footnote{http://manpages.ubuntu.com/manpages/trusty/man8/tc-netem.8.html}.
    The small implementation detail of \texttt{NetEm} is that by default it introduces traffic perturbations for the packets leaving the network interface but not the incoming packets~\cite{Ubuntu_Manpage_NetEm}.
    Hence, to simulate symmetrical network conditions I had to specify \texttt{NetEm} rules for both interfaces of the intermediate machine.
    For this reason, in other diagrams, I represent Network Emulator as separated into two sections (see Figure~\ref{fig:Wireshark_separation}).
    
    
    IP forwarding is enabled on the intermediate machine (B), redirecting \texttt{QUIC} packets from one subnet to another.
    Correctness of the experimental environment was tested by inspecting transit packets on the machine B.

    The intermediate machine adds only limited overhead.
    I derived these conclusions by comparing round-trip-times (using \texttt{ping} tool) and the maximum available \texttt{UDP} throughput (using \texttt{iperf3} tool) under two different conditions.
    At first, I measured performance when packets travel from one physical interface of machine A to its another physical interface via machine B.
    Then, I performed identical tests but without the intermediate machine meaning that packets were still forced to go from one physical interface to another via a loopback cable.
    Results were as follows: the maximum \texttt{UDP} throughput via machine B was 4.11 Gbits/sec [TODO: redo experiment] and via loopback cables this number was 9.91 Gbits/sec.
    In both case, throughput was measured on the receiver side.
    Similarly, after introducing the intermediate machine, the \texttt{RTT} increased from:
    
    \textbf{"RTT min/avg/max/mdev = 0.077/0.118/0.156/0.026 ms"}\\
    (\url{https://github.com/simonasmulevicius/Part-II-dissertation/blob/main/testing-scripts/test_overhead-of-intermediate-machine/test_maximum-iperf-troughput_via-loopback-cables/ping_result.txt})
    %[TODO: update these numbers with the new values from "test_ping-via-loopback-cables]
    
    to
    
    \textbf{"RTT min/avg/max/mdev = 0.188/0.262/0.353/0.065 ms"}\\
    (\url{https://github.com/simonasmulevicius/Part-II-dissertation/blob/main/testing-scripts/test_overhead-of-intermediate-machine/test_maximum-iperf-troughput_via-B/ping_result.txt})
    
    (Here each result was obtained after running ten \texttt{ping} experiments).
    
    % TODO
    \simon{TODO: add a table of results showing that lower RTT of looback cables increased throughput of ngtcp-h2load by about 10\%}
    % https://github.com/simonasmulevicius/Part-II-dissertation/blob/main/testing-scripts/test_overhead-of-intermediate-machine/test_unencrypted-ngtcp2-throughput_via-loopback_delay-0ms_uncorrelated-loss-0_0_percent_improved-null-encryption_with-command-line-option/result.ods
    

    Similarly, \texttt{TCP} throughput via loopback cable was 9.89 Gbis/sec.
    [TODO: what was TCP throughput via machine B?]


    Large segmentation offload and \texttt{TCP} segmentation offload mechanisms were in place on the machine A. 


\section{Benchmarking tools}
% Frame pointer points to the top/bottom of the stack (from https://www.youtube.com/watch?v=nXaxk27zwlk&ab_channel=CppCon)
\subsection{iperf3}
\texttt{Iperf3} is a tool that generates artificial \texttt{TCP} or \texttt{UDP} traffic and thus measures throughput of these protocols.
\texttt{Iperf3} performs throughput measurements between \texttt{iperf3} server and client.
We can assume that \texttt{UDP}'s throughput is a theoretical maximum of \texttt{QUIC} throughput as \texttt{QUIC} builds on top of \texttt{UDP}.
However, \texttt{UDP} does not provide a similar set of guarantees as \texttt{QUIC} does.
For example, \texttt{UDP} does not guarantee reliable packet delivery so the sender and receiver could see different throughput values.
Hence, to put \texttt{QUIC} into the perspective, it is worth comparing its throughput against the throughput of the similar \texttt{TCP} protocol.
An important aspect of \texttt{TCP} is that its congestion control mechanism allows sender to discover an appropriate sending bitrate.
In contrast, \texttt{UDP} does not take into account the state of the network.
Consequently, if unlimited \texttt{UDP} throughput is allowed, then one could flood the network by running \texttt{iperf3} to measure \texttt{UDP} throughput.
However, as shown in Figure~\ref{fig:Wireshark_separation}, performance analysis tests were executed on the separate testing network so no damage was done to the public network.


% TODO
[TODO: mention that one can adjust UDP send or receive (TODO check which one) buffer size]



\subsection{ping}
\texttt{Ping} is a network analysis tool used to measure the round trip time between the two communicating parties.
As mentioned in~\cite{internet-control-message-protocol-icmp}, \texttt{ping} uses Internet Control Message Protocol (or \texttt{ICMP} for short) to issue a request-reply pair.
Round trip time measurements were used to test the correctness of the testing environment (e.g. to measure additional network delay induced by the intermediate machine).
However, on \texttt{ping} could not be used to measure one-way delay because network delays can be asymmetric.


\subsection{Wireshark}

\texttt{Wireshark}\footnote{https://www.wireshark.org/} is a conventional tool used to inspect captured network packets (see Figure~\ref{fig:Wireshark_screenshot}).
\texttt{Wireshark} visualises key information about the packets -- source and destination \texttt{IP} addresses, type of protocol and time when the packet was received on the specified network interface.

    \begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{figs/Wireshark_screenshot.png}
    \caption[Example of \texttt{QUIC} packets captured with \texttt{Wireshark}]{Example of \texttt{QUIC} packets captured with \texttt{Wireshark}. This diagram demonstrates that \texttt{Wireshark} can decrypt, parse and display packet headers of \texttt{QUIC}. In particular, packet numbers (abbreviated PKN) are and displayed on the right hand side.}
    \label{fig:Wireshark_screenshot}
    \end{figure}
    
When required, I ran \texttt{Wireshark} on the intermediate machine to inspect size of the packets transferred between the \texttt{QUIC} client and server.
It is worth mentioning that \texttt{QUIC} packets are encrypted.
Hence, I had to share server's cryptographic certificate with \texttt{Wireshark} so that it could decrypt and extract relevant fields (e.g. packet number) of observed \texttt{QUIC} packets.

I used \texttt{Wireshark} in an ethical manner meaning that I only used it to analyse traffic between the dedicated network interfaces.
In other words, as demonstrated in Figure~\ref{fig:Wireshark_separation}, I did not capture packets from the college network because testing environment used separate network interfaces. 

    \begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{figs/Wireshark_separation.png}
    \caption[Separation of testing and college networks]{Separation of testing and college networks. I performed testing on a private network and I did not use \texttt{Wireshark} to capture packets from the college network}
    \label{fig:Wireshark_separation}
    \end{figure}



\subsection{perf}
\texttt{Perf}\footnote{https://perf.wiki.kernel.org/index.php/Main\_Page} is a performance analysis tool that measures CPU performance by sampling the call stack.

% TODO
\simon{TODO: differentiate between sampling based mechanisms and another family of perf analysis tools[TODO what is the name of that group?]}

\simon{TODO: limitations and overheads of sampling}

\simon{TODO: describe the selection process of frequencies (why 997 and not 1000)}



\subsection{Flame Graphs}
\texttt{Flame Graphs} \footnote{\url{http://www.brendangregg.com/flamegraphs.html}} is a performance analysis tool which is used to visualise the performance of the program.
In this project I used CPU \texttt{Flame Graphs} that show the aggregated call stacks of numerous samples (see Figure~\ref{fig:perf_results_of_h2load}).
To understand the \texttt{Flame Graphs} we should first look at the simple example diagram (see Figure~\ref{fig:Flame_Graphs_explanation}).

    \begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{figs/Flame_Graphs_explanation.png}
    \caption[Schematic diagram of \texttt{Flame Graphs}]{Schematic diagram of \texttt{Flame Graphs} adopted from Brendan Gregg's presentation~\cite{USENIX_ATC2017_flamegraphs}}
    \label{fig:Flame_Graphs_explanation}
    \end{figure}

Here y-axis of \texttt{Flame Graphs} represents the depth and frames of the call stack~\cite{CPU_Flame_graphs}.
For instance, we can see in Figure~\ref{fig:Flame_Graphs_explanation} that \textbf{function\_a()} invoked function calls \textbf{function\_b()} and \textbf{function\_g()}. 
However, an important point to mention is that x-axis of \texttt{Flame Graphs} does not represent time~\cite{CPU_Flame_graphs}.
Instead, function names are sorted alphabetically along the x-axis and it represents the approximate percentage of stack frames which were in the call stack~\cite{CPU_Flame_graphs}.
Hence, by looking at Figure~\ref{fig:Flame_Graphs_explanation} we can tell that \textbf{function\_b()} and its \enquote{children} functions spent more time on CPU than \textbf{function\_g()} and its corresponding functions but we can not tell the relative order in which these functions were called.
Furthermore, in order to better identify the most frequent function calls, stack frames sampled at different times can be merged if they have a shared ancestor~\cite{CPU_Flame_graphs}.
As a result, by looking at Figure~\ref{fig:Flame_Graphs_explanation} we can not differentiate whether or not function calls \textbf{function\_b()} and \textbf{function\_g()} did not interleave.

In the standard \texttt{Flame Graph}, different frames are coloured differently in order to increase visual contrast between the neighbouring cells in the diagram~\cite{CPU_Flame_graphs} (see yellow, orange and red rows in Figure~\ref{fig:perf_results_of_h2load}).
However, in this project, I am also using \texttt{Differential Flame Graphs} that depict the difference between the two \texttt{Flame Graphs}~\cite{Differential_Flame_Graphs}.
The structure of \texttt{Differential Flame Graph} is identical to the standard \texttt{Flame Graph} but the colouring information identifies which functions were more or less common in the second \texttt{Flame Graph} when compared with the reference \texttt{Flame Graph}~\cite{Differential_Flame_Graphs}.

% TODO
\simon{TODO: add an example of \texttt{Differential Flame Graph}}


% sampling based method



[MAYBE TODO: mention that I had to enable additional compiler flags to be able to see deeper call frames -- before that they were optimised by compiler and some stacks were partially anonymous  -- add a reason why this problem occurred -- compiler optimised one register?]

    \begin{figure}[ht]
    \centering
    \includegraphics[width=0.9\textwidth]{figs/perf_results_of_h2load.png}
    \caption[Typical \texttt{perf} results of running \texttt{h2load} client against \texttt{ngtcp2} server on the same machine (A), when packets are transferred via an intermediate machine (B)]{Typical \texttt{perf} results of running \texttt{h2load} client against \texttt{ngtcp2} server on the same machine (A), when packets are transferred via an intermediate machine (B). This graph shows that about 70\% of the time, default \texttt{ngtcp2} version spends doing cryptographic operations} 
    \label{fig:perf_results_of_h2load}
    \end{figure}
    
\subsection{qlog and qvis}
% TODO
\simon{TODO give a high-level overview of qlog format}

\simon{TODO: why is it hard to visualise QUIC's behaviour?}

\simon{Finally, add an example of qvis chart}


\section{Parameter Tuning}

\subsection{IP Version}

To make results comparable with older studies, I decided to disable IPv6 in the testing environment.
By specifying a particular IP version, we reduce the number of variable parameters.
Fortunately, at the time of writing, according to Google's IPv6 adoption tracker~\cite{IPv6_Adoption_Statistics}, only a third of all Internet users (30-35 \% to be precise) use IPv6 to connect to Google's services.
Hence, analysis involving IPv4 is still relevant today.

%TODO
\simon{TODO: Ubuntu 20.04 has different mechanism  to disable IPv6 -- check that it is still working}

%TODO
\simon{TODO: State that I had to revert this with MsQuic}

\subsection{Hyper-threading}\label{Hyperthreading_Subsection_Tag}

As Michael E. Thomadakis states on the 23rd page of~\cite{hyperthreading_book}, \texttt{hyper-threading} (more generally known as \texttt{simultaneous multi-threading}) is a thread allocation technique that allows two threads to run on the same physical core at the same time.
On the testing machines \texttt{hyper-threading} at first was implemented by assigning two virtual cores for every physical core (see Figure~\ref{fig:topology_with_hyperthreading}).
For instance, in this diagram core \enquote{L \#0} has two \enquote{processing units} marked as \enquote{PU L\#0} and \enquote{PU L\#1}.

    \begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{figs/topology_with_hyperthreading.png}
    \caption[Memory topology of machine A when \texttt{hyper-threading} is turned on]{Memory topology of machine A when \texttt{hyper-threading} is turned on (Figure generated by \texttt{lstopo} command)}
    \label{fig:topology_with_hyperthreading}
    \end{figure}

As stated in~\cite{hyperthreading_book}, this means that threads allocated to such virtual cores (also marked as \enquote{processing units} in the diagram above) would share the same physical resources (e.g. private L1 cache entries).
This is problematic for precise experiments.
On the one hand, a neighbouring thread might pre-fetch required data to the cache, but on the other hand, this thread might pollute the cache, thus hurting the performance of the thread which is being measured.
Hence, to reduce the potential performance variability, I had to disable \texttt{hyper-threading} on the testing machines.
The final version of architectural topology is shown in Figure~\ref{fig:memory_topology}. 
Correct configuration of \texttt{hyper-threading} was tested using different commands, such as \texttt{lscpu} and the aforementioned \texttt{lstopo}. 

    
    
\subsection{Separated Cores} \label{SeparatedCores_Subsection_Tag}
Machine A from Figure~\ref{fig:Physical_testing_environment} has four physical cores (see Figure~\ref{fig:memory_topology}).
To make performance tests even more predictable, I had to assign exclusive physical cores to the \texttt{QUIC} client and server using \texttt{taskset}\footnote{https://man7.org/linux/man-pages/man1/taskset.1.html} tool.
In particular, \texttt{ngtcp2} server was assigned the first core (marked as \enquote{P\#0} in Figure~\ref{fig:memory_topology}).
\texttt{QUIC} client (i.e. \texttt{ngtcp2} or \texttt{h2load} client) was assigned the second core (marked as \enquote{P\#1}).
Finally, remaining two cores (marked as \enquote{P\#2} and \enquote{P\#3}) were assigned to all the remaining system processes.
Robert Love refers to this technique of assigning particular processes to particular cores as \texttt{hard CPU affinity}~\cite{CPU_Affinity}.

    \begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{figs/memory_topology.png}
    \caption[Memory topology of machine A  when \texttt{hyper-threading} is turned off]{Memory topology of machine A  when \texttt{hyper-threading} is turned off (Figure generated by \texttt{lstopo} command)}
    \label{fig:memory_topology}
    \end{figure}

In addition, to evaluate the impact of core pinning, I measured throughput of \texttt{QUIC} under two different conditions by sending a file of the specified size over the intermediate machine.
At first, I allocated both \texttt{QUIC} server and client to the same core (see the red dashes in Figure~\ref{fig:Throughput_via_A-to-B-to-A_MTU=1500}).
Then, I performed identical throughput analysis tests with separated cores meaning that \texttt{QUIC} server and client resided on the two different cores.
Blue dashes in Figure~\ref{fig:Throughput_via_A-to-B-to-A_MTU=1500} demonstrate that core pinning almost doubled the maximum \texttt{QUIC} throughput for the transfer of large files (above 100MB).
However, impact of core pinning is not substantial when transferring small files.
One explanation of this could be that transmission time of small files is dominated by the overhead of networking stack and transmission time of a single packet.
As far as testing conditions are concerned, the intermediate machine was not configured to introduce additional explicit traffic perturbations.
    \begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{figs/Throughput via node B (A-to-B-to-A)_MTU=1500.png}
    \caption{Impact of core pinning for \texttt{QUIC} throughput}
    \label{fig:Throughput_via_A-to-B-to-A_MTU=1500}
    \end{figure}
% TODO
\simon{TODO: Am I talking here about iperf3 client-server pair or is it ngtcp2 pair?}

% TODO
\simon{TODO add a chart showing lower performance variability when using different cores for testing }

% TODO
\simon{TODO according to https://www.kernel.org/doc/ols/2009/ols2009-pages-169-184.pdf, "CPU affinity" reduces cache misses}

\subsection{GSO}
\begin{itemize}
  \item TODO introduce GSO (General Segmentation Offload)
  
  
  \item TODO add a chart showing GSO's impact on throughput
  
  
  \item TODO mention when GSO is relevant
  
  \item TODO state that from now on, GSO is used in all the remaining tests by default because GSO provided great performance improvements
\end{itemize}

\subsection{MTUs}
\begin{itemize}
  \item TODO introduce/refresh MTUs
  \item TODO demonstrate the Jumbo frames impact for iperf/\texttt{QUIC} throughput
  
  
  
    \begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{figs/Iperf3 UDP throughput using different MTUs (localhost).png}
    \caption{Impact of MTU size for iperf throughput (when packets travel via localhost)}
    \label{fig:MTU_impact_for_localhost_iperf_throughput}
    \end{figure}
    
    \begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{figs/Iperf3 UDP throughput using different MTUs (A1-to-B-to-A2).png}
    \caption{Impact of MTU size for iperf throughput (when packets travel via the intermediate machine)}
    \label{fig:}
    \end{figure}
  
  
  
% Please add the following required packages to your document preamble:
% \usepackage{multirow}
\begin{table}[H]

    \begin{tabular}{|c|c|c|c|c|c|}
    \hline
    \multirow{2}{*}{MTU (B)} & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Requested\\ file size\end{tabular}} & \multicolumn{4}{c|}{Throughput (MiB/s)}                                                     \\ \cline{3-6} 
                             &                                                                                & minimum & maximum & mean    & \begin{tabular}[c]{@{}c@{}}standard \\ deviation\end{tabular} \\ \hline
    \multirow{2}{*}{1280}    & 1MB                                                                            & 40.610  & 47.870  & 44.125  & 2.487                                                         \\ \cline{2-6} 
                             & 1GB                                                                            & 98.990  & 105.200 & 103.950 & 1.794                                                         \\ \hline
    \multirow{2}{*}{1500}    & 1MB                                                                            & 42.060  & 50.220  & 45.382  & 2.547                                                         \\ \cline{2-6} 
                             & 1GB                                                                            & 107.920 & 110.820 & 110.001 & 0.942                                                         \\ \hline
    \multirow{2}{*}{9000}    & 1MB                                                                            & 37.300  & 46.950  & 39.750  & 2.727                                                         \\ \cline{2-6} 
                             & 1GB                                                                            & 135.940 & 141.500 & 139.616 & 1.852                                                         \\ \hline
    \end{tabular}


    \begin{tabular}{|c|c|c|c|c|c|}
    \hline
    \multirow{2}{*}{MTU (B)} & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Requested\\ file size\end{tabular}} & \multicolumn{4}{c|}{Completion time (s)}                                                 \\ \cline{3-6} 
                             &                                                                                & minimum & maximum & mean  & \begin{tabular}[c]{@{}c@{}}standard\\ deviation\end{tabular} \\ \hline
    \multirow{2}{*}{1280}    & 1MB                                                                            & 0.020   & 0.023   & 0.022 & 0.001                                                        \\ \cline{2-6} 
                             & 1GB                                                                            & 9.070   & 9.640   & 9.180 & 0.166                                                        \\ \hline
    \multirow{2}{*}{1500}    & 1MB                                                                            & 0.019   & 0.023   & 0.021 & 0.001                                                        \\ \cline{2-6} 
                             & 1GB                                                                            & 8.610   & 8.840   & 8.674 & 0.075                                                        \\ \hline
    \multirow{2}{*}{9000}    & 1MB                                                                            & 0.020   & 0.026   & 0.024 & 0.001                                                        \\ \cline{2-6} 
                             & 1GB                                                                            & 6.740   & 7.020   & 6.834 & 0.092                                                        \\ \hline
    \end{tabular}




    \centering
    \caption[Impact of Jumbo frames on the throughput of \texttt{ngtcp2} Completion time required to transfer specified files]{Impact of Jumbo frames on the throughput of \texttt{ngtcp2} Completion time required to transfer specified files. In particular, this experiment measures \texttt{QUIC} throughput between the server and the client when they are pinned to two different cores on the same machine, and their packets travel via an intermediate machine (as demonstrated in Figure~\ref{fig:Physical_testing_environment}).
    Furthermore, a server uses a single thread, only a single stream is used, and a single file transfer is performed for each experiment.
    }
    \label{fig:Impact_of_Jumbo_frames_for_ngtcp2_throughput}
\end{table}

  
  \item 
  \simon{TODO show that Jumbo frames are not accepted in the wild Internet / TODO state that MTUs above 1500 bytes are not prevalent in the Internet}
  
  
  See Table~\ref{fig:Impact_of_Jumbo_frames_for_ngtcp2_throughput}.
  
  
\subsection{Interrupt Request Queue (IRQ) Balancing} 
Breno Henrique Leitao in his work suggested using~\cite{Tuning_10Gb_network_cards_on_Linux} Interrupt Request Queue (IRQ) Balancing to improve general throughput of the testing system.
By default, \texttt{IRQ} is enabled meaning that operating system aims to distribute the burden of handling interrupts evenly over all the processors~\cite{Tuning_10Gb_network_cards_on_Linux}.
The suggestion was to delegate processing of certain interrupts to specified processors hoping that this would improve performance of cores that were designated for the \texttt{QUIC} tests.
However, \texttt{IRQ} did not yield any noticeable effects for the \texttt{UDP} throughput measured by \texttt{iperf3} so I decided to leave the default \texttt{IRQ} settings on.
One plausible explanation for this insignificant improvement could be that the testing environment used already saturated network link.
In other words, measured maximum available throughput before and after experiment was around 9.8Gbits/second while the maximum theoretical limit of the link was 10Gbits/second. 


\subsection{Size of the Buffers} 

% TODO
\simon{TODO: 1. Update send and receive buffers according to: https://www.kernel.org/doc/ols/2009/ols2009-pages-169-184.pdf}

\simon{TODO: 2. State that adjusted buffers reduce UDP packet loss rate}
 
 \awm{ what are you writing here? make clear you mean txqueue and rxqueue as appropriate and not the "buffers" normally thought of as resident in the intermediate network devices}
  
\end{itemize}


\section{Baseline Measurements}

\subsection{\texttt{ping} Measurements}

\simon{MAYBE TODO: Move ping measurements from "Physical Setup" section to here}

\subsection{Throughput of Parallel \texttt{UDP} Streams} \label{section_Throughput_of_Parallel_UDP_Streams}

As illustrated in Figure~\ref{fig:QUIC_network_stack}, \texttt{QUIC} is built on top of \texttt{UDP}.
I measured throughput of \texttt{UDP} because the performance of \texttt{QUIC} is limited by this underlying protocol (see Table~\ref{fig:UDP_throughput_via_B_using_parallel_streams}).
In particular, I used testing topology similar to the one shown in  Figure~\ref{fig:Physical_testing_environment}.
However, in this experiment I replaced the \texttt{QUIC} client and the server with the corresponding \texttt{iperf3} client-server pair.
In addition, I did not add any additional packet delay or packet loss on the intermediate machine.
Furthermore, I repeated each individual test ten times and measured both the mean and standard deviation of these samples.
Here 1~Gbyte = 1000~MBytes = 1~000~000~KBytes = 1~000~000~000~Bytes.
As a side note, Large Receive Offload is disable on both the testing and intermediate machines.
















\begin{table}[H]
\begin{tabular}{|r|r|r|r|r|r|}
\hline
\multicolumn{1}{|c|}{\begin{tabular}[c]{@{}c@{}}Requested \\ file size \\ (MBytes)\end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}Number of \\ parallel \\ clients \\ (1 request \\ per client)\end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}Average\\ total \\ throughput \\ measured \\ on the \\ receiver's \\ side (MBit/s)\end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}Standard \\ deviation \\ of the \\ throughput \\ sample \\ (MBit/s)\end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}Average \\ total \\ completion \\ time (ms)\end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}Standard \\ deviation \\ of the\\ completion \\ time \\ sample (ms)\end{tabular}} \\ \hline
1                                                                                                & 1                                                                                                                          & 3248.07                                                                                                                                         & 284.23                                                                                                                           & *10.00\textgreater{}                                                                                                     & 0.00                                                                                                                             \\ \hline
1                                                                                                & 10                                                                                                                         & 2921.11                                                                                                                                         & 907.16                                                                                                                           & *10.00\textgreater{}                                                                                                     & 0.00                                                                                                                             \\ \hline
10                                                                                               & 1                                                                                                                          & 4410.93                                                                                                                                         & 75.89                                                                                                                            & 20.00                                                                                                    & 0.00                                                                                                                             \\ \hline
10                                                                                               & 10                                                                                                                         & 4434.55                                                                                                                                         & 181.87                                                                                                                           & 20.00                                                                                                    & 0.00                                                                                                                             \\ \hline
100                                                                                              & 1                                                                                                                          & 4561.26                                                                                                                                         & 56.09                                                                                                                            & 190.00                                                                                                   & 0.00                                                                                                                             \\ \hline
100                                                                                              & 10                                                                                                                         & 4442.07                                                                                                                                         & 212.95                                                                                                                           & 191.00                                                                                                   & 7.38                                                                                                                             \\ \hline
1000                                                                                             & 1                                                                                                                          & 4579.51                                                                                                                                         & 36.24                                                                                                                            & 1876.00                                                                                                  & 15.06                                                                                                                            \\ \hline
1000                                                                                             & 10                                                                                                                         & 4123.17                                                                                                                                         & 179.81                                                                                                                           & 2089.00                                                                                                  & 89.37                                                                                                                            \\ \hline
\end{tabular}
    \centering
    \caption[Impact of parallel streams for \texttt{UDP} throughput]{Impact of parallel streams for \texttt{UDP} throughput. Here packets travel via an intermediate machine. Here (*) identifies that the \texttt{iperf3} tool has a limited resolution of 0.01s to measure the completion time. Hence, transfer times of small files was reported to be 0s.}
    \label{fig:UDP_throughput_via_B_using_parallel_streams}
\end{table}












These experiments aimed to determine the impact of parallel \texttt{UDP} streams for the aggregated throughput of \texttt{UDP}.
As demonstrated in Table~\ref{fig:UDP_throughput_via_B_using_parallel_streams}, adding concurrent \texttt{UDP} clients increased the aggregated goodput when transferring small files, e.g. 1 or 10 MBytes in size.

However, for large files this effect is inverted -- additional concurrent \texttt{iperf3} clients decreased \texttt{UDP} throughput measured on the server-side.

This interesting effect could be explained by the fact that there is an associated overhead of maintaining additional \texttt{iperf3} clients.

%In other words, 
% TODO
\simon{TODO: explain these effects}

\simon{TODO: context/queue switches? for concurrent streams penalise the transfer of large concurrent files, but with small files, these switches are more frequent.
With large number of clients we can offer server a variety of packets it can process}

\simon{According to \url{https://fasterdata.es.net/performance-testing/network-troubleshooting-tools/iperf/multi-stream-iperf3/}, \texttt{iperf3} is a single threaded application so this might be a limiting testing factor}

In addition, single flow \texttt{UDP} throughput reaches a plateau as transferred file size increases.
This can be explained by the fact that there is a single \texttt{iperf3} server that processes all the packets.
Hence, the server and its associated stack could form the performance bottleneck.


% TODO
[TODO: function of UDP throughput in time]
[TODO: see Figure~\ref{fig:UDP_throughput_in_time}]
    \begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{figs/UDP_throughput_in_time.png}
    \caption[Change of \texttt{UDP} throughput in time when a single \texttt{iperf3} client sends \texttt{UDP} traffic to the \texttt{iperf3} server via an intermediate machine]{Change of \texttt{UDP} throughput in time when a single \texttt{iperf3} client sends \texttt{UDP} traffic to the \texttt{iperf3} server via an intermediate machine. Here throughput is measured at the granularity of 0.1 s}
    \label{fig:UDP_throughput_in_time}
    \end{figure}

\subsection{Throughput of Parallel \texttt{TCP} Streams}

Similarly, Table~\ref{fig:TCP_throughput_via_B_using_parallel_streams} demonstrates \texttt{TCP} throughput measurements using the same testing environment as described in the previous subsection (see \S~\ref{section_Throughput_of_Parallel_UDP_Streams}).
In other words, I repeated each individual experiment ten times, packets traveled via the intermediate machine that was configured not to add any additional packet delay or packet loss.
In addition, here 1~Gbyte = 1000~MBytes = 1~000~000~KBytes = 1~000~000~000~Bytes and 1~Gbit = 1000~Mbits = 1~000~000~Kbits = 1~000~000~000~bits.



\begin{table}[H]
\begin{tabular}{|r|r|r|r|r|r|}
\hline
\multicolumn{1}{|c|}{\begin{tabular}[c]{@{}c@{}}Requested \\ file size \\ (MBytes)\end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}Number of \\ parallel \\ clients \\ (1 request \\ per client)\end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}Average\\ total \\ throughput \\ measured \\ on the \\ receiver's \\ side (MBit/s)\end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}Standard \\ deviation \\ of the \\ throughput \\ sample \\ (MBit/s)\end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}Average \\ total \\ completion \\ time (ms)\end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}Standard \\ deviation \\ of the\\ completion \\ time \\ sample (ms)\end{tabular}} \\ \hline
1                                                                                                & 1                                                                                                                          & 2701.53                                                                                                                                         & 681.26                                                                                                                           & *10.00\textgreater{}                                                                                     & 0.00                                                                                                                             \\ \hline
1                                                                                                & 10                                                                                                                         & 4930.62                                                                                                                                         & 858.86                                                                                                                           & *10.00\textgreater{}                                                                                     & 0.00                                                                                                                             \\ \hline
10                                                                                               & 1                                                                                                                          & 4340.06                                                                                                                                         & 1293.96                                                                                                                          & 20.00                                                                                                    & 9.43                                                                                                                             \\ \hline
10                                                                                               & 10                                                                                                                         & 6931.00                                                                                                                                         & 1134.74                                                                                                                          & 10.00                                                                                                    & 0.00                                                                                                                             \\ \hline
100                                                                                              & 1                                                                                                                          & 7548.41                                                                                                                                         & 1185.02                                                                                                                          & 111.00                                                                                                   & 18.53                                                                                                                            \\ \hline
100                                                                                              & 10                                                                                                                         & 7307.89                                                                                                                                         & 1078.34                                                                                                                          & 102.00                                                                                                   & 12.29                                                                                                                            \\ \hline
1000                                                                                             & 1                                                                                                                          & 8437.46                                                                                                                                         & 705.77                                                                                                                           & 1018.00                                                                                                  & 79.55                                                                                                                            \\ \hline
1000                                                                                             & 10                                                                                                                         & 9534.83                                                                                                                                         & 381.91                                                                                                                           & 900.00                                                                                                   & 33.67                                                                                                                            \\ \hline
\end{tabular}
    \centering
    \caption[Impact of parallel streams for \texttt{TCP} throughput]{Impact of parallel streams for \texttt{TCP} throughput. Here packets travel via an intermediate machine. Here (*) refers to the same problem described in Figure~\ref{fig:UDP_throughput_via_B_using_parallel_streams}.}
    \label{fig:TCP_throughput_via_B_using_parallel_streams}
\end{table}


Table~\ref{fig:TCP_throughput_via_B_using_parallel_streams} shows the effect of increased transferred file size for the throughput of \texttt{TCP}.
Naturally, it takes less time to transfer small file than the large one.
However, this means that \texttt{TCP} spends most of the time in the \enquote{slow start} phase when sending small files because their transfer time is shorter than the duration of the \enquote{slow start}.
As a result, \texttt{TCP}'s throughput when sending small files is low.
In contrast, transferring larger files allows \texttt{TCP} to discover the maximum sustainable network capacity.
Thus, the \texttt{TCP} throughput is noticeably larger when sending larger files. 
In addition, transfer of large files allows \texttt{TCP} to amortise the overhead of initial \texttt{TCP} handshake.
Hence, when sending 1GByte of data, \texttt{TCP} was able to approach the maximum link capacity that was 10~Gbits/s.


\simon{describe function of TCP throughput in time (see Figure~\ref{fig:TCP_throughput_in_time})}


\simon{First 4 rows of the table - there are 4 different experiments with different throughputs (differ by at least the factor of 2) and the average completion time of all of them was around 10ms. Hence, this example demonstrates that iperf3 does not have sufficient resolution to capture and visualise the effect of slow start. }

% TODO
\simon{TODO: comparison of TCP vs UDP}

\simon{According to https://support.cumulusnetworks.com/hc/en-us/articles/216509388-Throughput-Testing-and-Troubleshooting, TCP might have better offloading support than UDP meaning that their throughouts may not be comparable}

    \begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{figs/TCP_throughput_in_time.png}
    \caption[Change of \texttt{TCP} throughput in time when a single \texttt{iperf3} client sends \texttt{TCP} traffic to the \texttt{iperf3} server via an intermediate machine]{Change of \texttt{TCP} throughput in time when a single \texttt{iperf3} client sends \texttt{TCP} traffic to the \texttt{iperf3} server via an intermediate machine. Here throughput is measured at the granularity of 0.1 s}
    \label{fig:TCP_throughput_in_time}
    \end{figure}
    
    
    
    
\simon{Why did iperf3 report lower throughput for UDP? According to \url{https://fuchsia.googlesource.com/third_party/iperf/+/3.0.2/README.md}, iperf3 might not be the best tool for high UDP throughput measurements. The source recommends using another tool nuttcp instead }
    
% SERVER: ip netns exec mr_server nuttcp -S
% CLIENT: taskset -c 1 ip netns exec mr_client nuttcp  -l1448 -T30 -u -w40m -Ru -i1 10.2.2.101

\subsection{Throughput of Parallel \texttt{TCP} Streams that use \texttt{TLS}}
 
Throughput measurements of \texttt{TCP} with \texttt{TLS} are relevant because these values form an equal comparison with \texttt{QUIC} throughput.
In other words, as I have already mentioned in Section \ref{QUIC_details_section}, \texttt{QUIC} uses cryptographic handshakes by default meaning that for a fair comparison with \texttt{QUIC}, \texttt{TCP} also has to include \texttt{Transport Layer Security} layer.

Unfortunately, I could not measure the throughput of parallel \texttt{TCP} streams that use \texttt{TLS}.
It turns out that \texttt{iperf3}, the aforementioned throughput measurement tool, currently does not generate combined \texttt{TCP} and \texttt{TLS} throughput.
However, I found one extension of \texttt{iperf3} that claims to provide support for \texttt{TLS} \footnote{\url{https://github.com/Mic92/iperf-3.7}} but it had build errors so I did not use this extension.
In addition, I tried using \texttt{MsQuic} performance analysis tools that have explicit options to perform measurements with \texttt{TCP} rather than \texttt{QUIC}. 
But this functionality is not supported on Linux.
Unfortunately, I used \texttt{Ubuntu 20.04 LTS (Focal Fossa)} operating system on both machines in the testing environment (shown in Figure~\ref{fig:Physical_testing_environment}).
In the future, \texttt{MsQuic} tools may provide better support for the family of Unix operating systems meaning that subsequent studies could take throughput of \texttt{TCP} with \texttt{TLS} into account.


\subsection{Throughput of Parallel \texttt{QUIC} Streams}

% TODO
\simon{TODO: describe testing conditions in prose}

Number of tests for each experiment: 10

No added packet delay

No added packet loss

A1-B-A2

Uses encrypted ngtcp2-h2load version

GSO enabled


Here 1~Gbyte = 1000~MBytes = 1~000~000~KBytes = 1~000~000~000~Bytes.




\begin{table}[H]
\begin{tabular}{|r|r|r|r|r|r|}
\hline
\multicolumn{1}{|c|}{\begin{tabular}[c]{@{}c@{}}Requested \\ file size \\ (MBytes)\end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}Number of \\ parallel \\ clients \\ (1 request \\ per client)\end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}Average\\ total \\ throughput \\ measured \\ on the \\ receiver's \\ side (MBit/s)\end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}Standard \\ deviation \\ of the \\ throughput \\ sample \\ (MBit/s)\end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}Average \\ total \\ completion \\ time (ms)\end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}Standard \\ deviation \\ of the\\ completion \\ time \\ sample (ms)\end{tabular}} \\ \hline
1                                                                                                & 1                                                                                                                          & 393.64                                                                                                                                          & 20.53                                                                                                                            & 20.38                                                                                                    & 1.07                                                                                                                             \\ \hline
1                                                                                                & 10                                                                                                                         & 594.66                                                                                                                                          & 4.40                                                                                                                             & 134.59                                                                                                   & 1.00                                                                                                                             \\ \hline
10                                                                                               & 1                                                                                                                          & 706.30                                                                                                                                          & 11.19                                                                                                                            & 113.33                                                                                                   & 1.82                                                                                                                             \\ \hline
10                                                                                               & 10                                                                                                                         & 766.00                                                                                                                                          & 2.94                                                                                                                             & 1044.00                                                                                                  & 5.16                                                                                                                             \\ \hline
100                                                                                              & 1                                                                                                                          & 767.72                                                                                                                                          & 3.39                                                                                                                             & 1042.00                                                                                                  & 4.22                                                                                                                             \\ \hline
100                                                                                              & 10                                                                                                                         & 788.40                                                                                                                                          & 2.33                                                                                                                             & 10150.00                                                                                                 & 29.44                                                                                                                            \\ \hline
1000                                                                                             & 1                                                                                                                          & 755.04                                                                                                                                          & 15.51                                                                                                                            & 10602.00                                                                                                 & 219.53                                                                                                                           \\ \hline
1000                                                                                             & 10                                                                                                                         & 685.84                                                                                                                                          & 7.55                                                                                                                             & 116694.00                                                                                                & 1258.09                                                                                                                          \\ \hline
\end{tabular}
    \centering
    \caption{Impact of parallel requests for encrypted \texttt{QUIC} throughput. Here packets travel via an intermediate machine}
    \label{fig:QUIC_throughput_via_B_using_parallel_requests}
    
    
    \simon{TODO: IDEA: behaves like UDP}
    
    \simon{h2load experiment is probably sending 1 or 10 separate "files" while iperf3 is probably sending just a single "file" over 1 or 10 connections}
\end{table}
















\section{Impact of Cryptographic Operations}
% TODO:
% Ran experiments with different network conditions:
% > delay
% > uncorrelated packet loss -- meaning that the probability of loosing a packet does not increase if the previous packet is lost
% > (TODO) packet reordering

% conditions:
%  sampling frequency=997 (step locking)
%  MTU=default(1252)
%  number of samples



\subsection{Performance Comparison of encrypted and unencrypted versions of \texttt{ngtcp2}}




\begin{table}[H]
\begin{tabular}{|r|r|r|r|r|r|}
\hline
\multicolumn{1}{|c|}{\begin{tabular}[c]{@{}c@{}}Requested \\ file size \\ (MBytes)\end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}Number of \\ parallel \\ clients \\ (1 request \\ per client)\end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}Average\\ total \\ throughput \\ measured \\ on the \\ receiver's \\ side (MBit/s)\end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}Standard \\ deviation \\ of the \\ throughput \\ sample \\ (MBit/s)\end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}Average \\ total \\ completion \\ time (ms)\end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}Standard \\ deviation \\ of the\\ completion \\ time \\ sample (ms)\end{tabular}} \\ \hline
1                                                                                                & 1                                                                                                                          & 713.35                                                                                                                                          & 44.04                                                                                                                            & 11.26                                                                                                    & 0.70                                                                                                                             \\ \hline
1                                                                                                & 10                                                                                                                         & 1325.47                                                                                                                                         & 12.02                                                                                                                            & 60.39                                                                                                    & 0.55                                                                                                                             \\ \hline
10                                                                                               & 1                                                                                                                          & 2092.74                                                                                                                                         & 19.25                                                                                                                            & 38.24                                                                                                    & 0.35                                                                                                                             \\ \hline
10                                                                                               & 10                                                                                                                         & 2411.86                                                                                                                                         & 9.94                                                                                                                             & 331.81                                                                                                   & 1.37                                                                                                                             \\ \hline
100                                                                                              & 1                                                                                                                          & 2579.74                                                                                                                                         & 20.39                                                                                                                            & 310.22                                                                                                   & 2.48                                                                                                                             \\ \hline
100                                                                                              & 10                                                                                                                         & 2642.97                                                                                                                                         & 27.40                                                                                                                            & 3029.00                                                                                                  & 31.07                                                                                                                            \\ \hline
1000                                                                                             & 1                                                                                                                          & 2661.93                                                                                                                                         & 7.01                                                                                                                             & 3006.00                                                                                                  & 8.43                                                                                                                             \\ \hline
1000                                                                                             & 10                                                                                                                         & 2557.58                                                                                                                                         & 73.76                                                                                                                            & 31312.00                                                                                                 & 891.61                                                                                                                           \\ \hline
\end{tabular}
\end{table}




\simon{0. Add throughput measurements of both encrypted and unencrypted versions}

\simon{1. Add a flame chart of ENCRYPTED ngtcp2 behaviour over some standard link and sufficiently large requested file size}

\simon{2. Add a flame chart of UNENCRYPTED ngtcp2 behaviour over the same link and sufficiently large requested file size}




\subsection{Performance Comparison of \enquote{Null encryption} in \texttt{MsQuic} and \texttt{ngtcp2}}

As I have already mentioned, \texttt{MsQuic}, \texttt{Microsoft's} implementation of \texttt{QUIC}, has the pre-built option to disable cryptography.
\enquote{Null encryption} mechanism of  \texttt{MsQuic} works as follows.
At first, communicating end hosts still have to complete a secure handshake~\cite{banks-quic-disable-encryption-00}.
After that, if both client and server express their will to turn off encryption, then plaintext packets are used for communications (i.e. both packet headers and payloads are unencrypted)~\cite{banks-quic-disable-encryption-00}.
However, according to Mr N. Banks, one drawback of continuing to use encryption for the first \texttt{QUIC} handshake is that performance of \texttt{QUIC} handshake is not improved.

\simon{Add a chart showing throughput of encrypted/encrypted ngtcp2 throughput + encrypted/encrypted MsQuic throughput}


\subsection{Performance Comparison of \enquote{Null Encryption} in Application Layer}

\simon{Compare througputs of HTTP/3 with null crypto vs HTTP/2 with "--no-tls-proto" (h2load client supports that, now I just need to find HTTP/2 server)}

\section{\texttt{QUIC} Performance Evaluation}


\subsection{Impact of Link Delay}

\simon{Add a graph that would demonstrate how throughput of unencrypted ngtcp2 changes with the increasing additional packet DELAY. No packet loss should be added. Probably I should use similar delays as the ones that were used in other papers (e.g. +10ms, +50ms, +100ms).}

\simon{What requested file size should I use for these measurements?}

\subsection{Impact of Packet Loss}

\simon{Add a graph that would demonstrate how throughput of unencrypted ngtcp2 changes with the increasing additional packet LOSS. }

\simon{Use packet loss: 1\%, 0.1\%, 0.01\%, 0.001\%}

\simon{In addition, these loss values should be equal to the ones used in MsQuic performance dashboard}

\simon{What requested file size should I use for these measurements?}





\section{Final the Most Optimised Version Of \texttt{QUIC}}

\simon{It might be an interesting section to combine all of the performance boosting ideas (GSO, null-crypto, Jumbo frames, large frame sizes) to create ngtcp2 version with the highest throughput}






\chapter{Conclusion}
% ------------------------------------------------
%This chapter is likely to be very short and it may well refer back to the Introduction. It might offer a reflection on the lessons learned and explain how you would have planned the project if starting again with the benefit of hindsight.


% FROM: https://www.cst.cam.ac.uk/teaching/part-ii/projects/assessment
%Clearly presented argument demonstrating success criteria met.
%Good or excellent evidence of critical thought and interpretation of the results which substantiate any claims of success, improvements or novelty.
%Conclusions provide an effective summary of work completed along with good future work.
%Personal reflection on the lessons learned.
% ------------------------------------------------

\section{Summary}

\simon{Read about energy efficiency and application of QUIC for IoT https://calendar.perfplanet.com/2018/quic-and-http-3-too-big-to-fail/}

\awm{Don't forget - make a CONCLUSION too}

\section{Reflection}
Before starting the project, prior expertise working with the \texttt{NetFPGA} platform would have substantially helped.
In particular, hands-on experience with the reference hardware projects during the summer before Part II would have allowed me to start working on the implementation of the hardware offloading project during the Michaelmas term.


\section{Future Work}
% TODO
\simon{TODO: suggest offloading crypto to hardware (as Gianni's team has already suggested)}

\simon{TODO: critique that offloading \texttt{QUIC} to hardware might stifle innovation in the long term. }

\simon{TODO: for example, look into invariants of \texttt{QUIC} and check if such offloading would be acceptable}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% the bibliography
\addcontentsline{toc}{chapter}{Bibliography}
\bibliography{refs}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% the appendices
\appendix

\chapter{Preparation script from \texttt{\textasciitilde/.zshrc}} \label{preparation_script_from_zshrc}

\begin{verbatim}
# ----------------------------------------------------

echo "0. Running ~/.zshrc"

echo "Setting up go environment"
export PATH=$PATH:/usr/local/go/bin

# ...

# echo "2. Setting X11-forwarding"
# xauth add $(xauth -f ~user109/.Xauthority list | tail -1)

echo "3. List of available ports"
ifconfig -a

# ...

echo "6.  Waking up network interfaces:"
echo "6.0 Deleting old assignment of network interfaces"
ip netns delete mr_client
ip netns delete mr_server
ip netns add mr_client
ip netns add mr_server

echo "6.1 Initial configuration:"
sleep 4
ip link set eth2 up
ip link set eth3 up
ip link set nf0 up
ip link set nf1 up
ip link set nf2 up
ip link set nf3 up
sleep 4

export client_subnet="10.1.1"
export server_subnet="10.2.2"
export client_IP=${client_subnet}".100"
export server_IP=${server_subnet}".101"
export client_default_gateway_IP=${client_subnet}".1"
export server_default_gateway_IP=${server_subnet}".1"

echo "client_IP: $client_IP"
echo "server_IP: $server_IP"
echo "client_default_gateway_IP: $client_default_gateway_IP"
echo "server_default_gateway_IP: $server_default_gateway_IP"

echo "6.2 Setting IP addresses for nf0, nf1, eth2, eth3"
ifconfig nf0  10.4.4.100 netmask 255.255.255.0
ifconfig nf1  10.4.4.101 netmask 255.255.255.0
ifconfig nf2  10.4.4.102 netmask 255.255.255.0
ifconfig nf3  10.4.4.103 netmask 255.255.255.0
ifconfig eth2 $client_IP netmask 255.255.255.0
ifconfig eth3 $server_IP netmask 255.255.255.0

ip link set dev eth2 mtu 1500
ip link set dev eth3 mtu 1500

ifconfig -a


echo "6.3 Setting virtual namespaces"
ip link set dev eth2 netns mr_client
ip link set dev eth3 netns mr_server
ip netns exec mr_client ip addr add $client_IP/24 dev eth2
ip netns exec mr_server ip addr add $server_IP/24 dev eth3
ip netns exec mr_client ip link set dev eth2 up
ip netns exec mr_server ip link set dev eth3 up
sleep 2
ip netns exec mr_client route add default gw $client_default_gateway_IP eth2
ip netns exec mr_server route add default gw $server_default_gateway_IP eth3

ip netns exec mr_client ip route show
ip netns exec mr_server ip route show

echo "6.3.1 Configuration of network namespaces"
ip netns exec mr_client ip addr list | grep "eth2"
ip netns exec mr_server ip addr list | grep "eth3"
echo "\n"

ip netns exec mr_client ping -c1 "$server_IP" | grep "received"
ip netns exec mr_client ping -c1 "$client_default_gateway_IP" | grep "received"
ip netns exec mr_server ping -c1 "$client_IP" | grep "received"
ip netns exec mr_server ping -c1 "$server_default_gateway_IP" | grep "received"

echo "\n"


cd /root/evaluation/Part-II-dissertation

echo "8. Setting SSLKEYLOGFILE"
export SSLKEYLOGFILE=/root/evaluation/unencrypted_stack/ngtcp2/examples/server.key
echo " SSLKEYLOGFILE: $SSLKEYLOGFILE"

echo "9. Turn off hyperthreading"
echo off > /sys/devices/system/cpu/smt/control
lscpu | grep "per core"

# ...

echo "11. checking if offload is turned off..."
echo "  CLIENT:"
ip netns exec mr_client ethtool -K eth2 lro off
ip netns exec mr_client ethtool -K eth2 gso off
ip netns exec mr_client ethtool -k eth2 | grep large-receive-offload
ip netns exec mr_client ethtool -k eth2 | grep tcp-segmentation-offload

echo "  SERVER:"
ip netns exec mr_server ethtool -K eth3 lro off
ip netns exec mr_server ethtool -K eth3 gso off
ip netns exec mr_server ethtool -k eth3 | grep large-receive-offload
ip netns exec mr_server ethtool -k eth3 | grep tcp-segmentation-offload

#
# ----------------------------------------------------

\end{verbatim}

\chapter{Source B}

    \section{appendix section}\label{referencedAppendixTag}


\chapter{Project Proposal}

\input{proposal}

 \end{document}
